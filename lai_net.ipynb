{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start importing required libraries...\n",
      "Done importing\n",
      "bcftools has been loaded\n"
     ]
    }
   ],
   "source": [
    "print('Start importing required libraries...')\n",
    "import os, sys, time\n",
    "import subprocess\n",
    "sys.path.append('../')\n",
    "from tqdm.auto import tqdm\n",
    "import allel\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from collections import Counter\n",
    "import gzip\n",
    "import tagore\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from lainet.models.network_constructor import get_network\n",
    "from lainet.utils.eval import compute_accuracy, AccuracyLogger, complete_sk_eval, print_sk_eval\n",
    "from lainet.utils.reader import load_founders_from_vcf_and_map, load_results_file\n",
    "from lainet.utils.output_writer import get_meta_data, write_msp_tsv\n",
    "from lainet.training import train_main, eval_predictions\n",
    "from lainet.inference import inference_main \n",
    "\n",
    "from utils.format_file import add_result, naming_file, output_name\n",
    "from utils.format_file import naming_file, extract_from_same_file, extract_from_file,output_name_mixed\n",
    "\n",
    "print('Done importing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing bcftools\n",
    "exec(open(\"/shared/software/modules/4.6.1/init/python.py\").read(), globals())\n",
    "module(\"load\", \"bcftools\")\n",
    "\n",
    "print(\"bcftools has been loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "genetic_map_file =  \"../data/input/real/allchrs_b37.gmap\"\n",
    "config_path = 'configs/default.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FORMATING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create the file for the train and the test.\n",
    "if you already have your files you can **skip this section**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is three choices, **you only need to chose of the option**: <br>\n",
    "    1. you want to split only **one file** into the train and test    \n",
    "    2. you want to use **one file (or a part of ) for the train** and **another file (or a part of) for the test** (the files must have different samples    \n",
    "    3. you want to **mix samples for one file and another** to do the train and the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Extracting train and test from the same file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define some characteristics of our samples. We need to know how many pop, if it's artificial or real and how many sample we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSNP='65k'\n",
    "pop=['AFR','EUR','EAS','AMR','SAS']\n",
    "npop=len(pop)\n",
    "\n",
    "\n",
    "real=True #put true if real, false if artificial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/real/65k_SNP/5pop_690train.vcf.gz ../data/input/real/65k_SNP/5pop_690train.tsv ../data/input/real/65k_SNP/5pop_690train.smap\n",
      "../data/input/real/65k_SNP/\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "nsamplepop=138\n",
    "\n",
    "test_file,test_list_file,test_map_file,prefix=naming_file(False,real,nsamplepop,npop,nSNP,'../data/input/')\n",
    "print(test_file,test_list_file,test_map_file)\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/real/65k_SNP/5pop_1045test.vcf.gz ../data/input/real/65k_SNP/5pop_1045test.tsv ../data/input/real/65k_SNP/5pop_1045test.smap\n",
      "../data/input/real/65k_SNP/\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "nquerypop=209\n",
    "\n",
    "train_file,train_list_file,train_map_file,prefix=naming_file(True,real,nquerypop,npop,nSNP,'../data/input/')\n",
    "print(train_file,train_list_file,train_map_file)\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/real/65k_SNP/reference.vcf.gz\n",
      "../data/input/real/65k_SNP/reference.smap\n"
     ]
    }
   ],
   "source": [
    "reference_file=prefix+'reference.vcf.gz'\n",
    "reference_map_file=prefix+'reference.smap'\n",
    "print(reference_file)\n",
    "print(reference_map_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selecting samples...\n",
      "\n",
      "{'AFR': 209, 'EUR': 209, 'EAS': 209}\n",
      "{'AFR': 138, 'EUR': 138, 'EAS': 138}\n",
      "\n",
      "\n",
      "Running in command line: \n",
      "\t bcftools view -S ../data/input/real/65k_SNP/3pop_627test.tsv -Ov -o ../data/input/real/65k_SNP/3pop_627test.vcf.gz ../data/input/real/65k_SNP/reference.vcf.gz \n",
      "\t bcftools view -S ../data/input/real/65k_SNP/3pop_414train.tsv -Ov -o ../data/input/real/65k_SNP/3pop_414train.vcf.gz ../data/input/real/65k_SNP/reference.vcf.gz\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "extract_from_same_file(reference_file,reference_map_file,nquerypop,nsamplepop,train_map_file,test_map_file,train_list_file,test_list_file,train_file,test_file,pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/output_lainet/65k_SNP/train690_rAFR-rEUR-rEAS-rAMR-rSAS-test1045_rAFR-rEUR-rEAS-rAMR-rSAS-/\n"
     ]
    }
   ],
   "source": [
    "output_basename=output_name('lainet',nSNP,nsamplepop,nquerypop,pop,real,real)\n",
    "print(output_basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Extracting train and test from two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSNP='65k'\n",
    "pop=['AFR','EUR','EAS']\n",
    "npop=len(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/artificial/65k_SNP/3pop_414train.vcf.gz ../data/input/artificial/65k_SNP/3pop_414train.tsv ../data/input/artificial/65k_SNP/3pop_414train.smap\n",
      "../data/input/artificial/65k_SNP/\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "real_train=False\n",
    "nsamplepop=138\n",
    "\n",
    "train_file,train_list_file,train_map_file,data_folder_s=naming_file(False,real_train,nsamplepop,npop,nSNP,'../data/input/')\n",
    "print(train_file,train_list_file,train_map_file)\n",
    "print(data_folder_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/artificial/65k_SNP/reference.vcf.gz\n",
      "../data/input/artificial/65k_SNP/reference.smap\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "reference_file_s=data_folder_s+'reference.vcf.gz'\n",
    "reference_map_file_s=data_folder_s+'reference.smap'\n",
    "print(reference_file_s)\n",
    "print(reference_map_file_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/real/65k_SNP/3pop_627test.vcf.gz ../data/input/real/65k_SNP/3pop_627test.tsv ../data/input/real/65k_SNP/3pop_627test.smap\n",
      "../data/input/real/65k_SNP/\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "real_test=True\n",
    "nquerypop=209\n",
    "\n",
    "test_file,test_list_file,test_map_file,data_folder_q=naming_file(True,real_test,nquerypop,npop,nSNP,'../data/input/')\n",
    "print(test_file,test_list_file,test_map_file)\n",
    "print(data_folder_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/real/65k_SNP/reference.vcf.gz\n",
      "../data/input/real/65k_SNP/reference.smap\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "reference_file_q=data_folder_q+'reference.vcf.gz'\n",
    "reference_map_file_q=data_folder_q+'reference.smap'\n",
    "print(reference_file_q)\n",
    "print(reference_map_file_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AFR': 138, 'EUR': 138, 'EAS': 138}\n",
      "\n",
      "\n",
      "Running in command line: \n",
      "\t bcftools view -S ../data/input/artificial/65k_SNP/3pop_414train.tsv -Ov -o ../data/input/artificial/65k_SNP/3pop_414train.vcf.gz ../data/input/artificial/65k_SNP/reference.vcf.gz\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "extract_from_file(reference_file_s,reference_map_file_s,nsamplepop,train_map_file,train_list_file,train_file,pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AFR': 209, 'EUR': 209, 'EAS': 209}\n",
      "\n",
      "\n",
      "Running in command line: \n",
      "\t bcftools view -S ../data/input/real/65k_SNP/3pop_627test.tsv -Ov -o ../data/input/real/65k_SNP/3pop_627test.vcf.gz ../data/input/real/65k_SNP/reference.vcf.gz\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "extract_from_file(reference_file_q,reference_map_file_q,nquerypop,test_map_file,test_list_file,test_file,pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/output_lainet/65k_SNP/train414_aAFR-aEUR-aEAS-test627_rAFR-rEUR-rEAS-/\n"
     ]
    }
   ],
   "source": [
    "output_basename=output_name('lainet',nSNP,nsamplepop,nquerypop,pop,real_train,real_test)\n",
    "print(output_basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Mixing artificial and real genome for the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSNP='65k'\n",
    "rm=True # if true when merging, old files are removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to extract real sample and artificial samples into two vcf files and then we will merge those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "ARTIFICIAL TRAIN SET\n",
      "../data/input/artificial/65k_SNP/1pop_300train.vcf.gz ../data/input/artificial/65k_SNP/1pop_300train.tsv ../data/input/artificial/65k_SNP/1pop_300train.smap\n",
      "../data/input/artificial/65k_SNP/\n",
      "{'EUR': 300}\n",
      "\n",
      "\n",
      "Running in command line: \n",
      "\t bcftools view -S ../data/input/artificial/65k_SNP/1pop_300train.tsv -Ov -o ../data/input/artificial/65k_SNP/1pop_300train.vcf.gz ../data/input/artificial/65k_SNP/reference.vcf.gz\n",
      "Done\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#artificial train set\n",
    "pop_ta=['EUR']\n",
    "\n",
    "npop_1=len(pop_ta)\n",
    "nsamplepop_1=300\n",
    "\n",
    "train_file,train_list_file,train_map_file,prefix=naming_file(False,False,nsamplepop_1,npop_1,nSNP,'../data/input/')\n",
    "print(\"-\"*100)\n",
    "\n",
    "print('ARTIFICIAL TRAIN SET')\n",
    "\n",
    "print(train_file,train_list_file,train_map_file)\n",
    "print(prefix)\n",
    "\n",
    "reference_file=prefix+'reference.vcf.gz'\n",
    "reference_map_file=prefix+'reference.smap'\n",
    "\n",
    "extract_from_file(reference_file,reference_map_file,nsamplepop_1,train_map_file,train_list_file,train_file,pop_ta)\n",
    "print(\"-\"*100)\n",
    "sfile1=train_file\n",
    "sfile1_tsv=train_list_file\n",
    "sfile1_map=train_map_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "REAL TRAIN SET\n",
      "../data/input/real/65k_SNP/2pop_600train.vcf.gz ../data/input/real/65k_SNP/2pop_600train.tsv ../data/input/real/65k_SNP/2pop_600train.smap\n",
      "../data/input/real/65k_SNP/\n",
      "----------------------------------------------------------------------------------------------------\n",
      "REAL QUERY SET1\n",
      "../data/input/real/65k_SNP/2pop_404test.vcf.gz ../data/input/real/65k_SNP/2pop_404test.tsv ../data/input/real/65k_SNP/2pop_404test.smap\n",
      "../data/input/real/65k_SNP/\n",
      "----------------------------------------------------------------------------------------------------\n",
      "../data/input/real/65k_SNP/reference.vcf.gz\n",
      "../data/input/real/65k_SNP/reference.smap\n",
      "Randomly selecting samples...\n",
      "\n",
      "{'AFR': 202, 'EAS': 202}\n",
      "{'AFR': 300, 'EAS': 300}\n",
      "\n",
      "\n",
      "Running in command line: \n",
      "\t bcftools view -S ../data/input/real/65k_SNP/2pop_600train.tsv -Ov -o ../data/input/real/65k_SNP/2pop_600train.vcf.gz ../data/input/real/65k_SNP/reference.vcf.gz \n",
      "\t bcftools view -S ../data/input/real/65k_SNP/2pop_404test.tsv -Ov -o ../data/input/real/65k_SNP/2pop_404test.vcf.gz ../data/input/real/65k_SNP/reference.vcf.gz\n",
      "\n",
      "Done\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#real train set\n",
    "pop_tr=['AFR','EAS']\n",
    "\n",
    "npop_2=len(pop_tr)\n",
    "nsamplepop_2=300\n",
    "\n",
    "train_file,train_list_file,train_map_file,prefix=naming_file(False,True,nsamplepop_2,npop_2,nSNP,'../data/input/')\n",
    "print(\"-\"*100)\n",
    "print('REAL TRAIN SET')\n",
    "\n",
    "print(train_file,train_list_file,train_map_file)\n",
    "print(prefix)\n",
    "\n",
    "\n",
    "#real query set\n",
    "print(\"-\"*100)\n",
    "print('REAL QUERY SET1')\n",
    "nquerypop_1=202\n",
    "\n",
    "query_file,query_list_file,query_map_file,prefix=naming_file(True,True,nquerypop_1,npop_2,nSNP,'../data/input/')\n",
    "print(query_file,query_list_file,query_map_file)\n",
    "print(prefix)\n",
    "\n",
    "print(\"-\"*100)\n",
    "reference_file=prefix+'reference.vcf.gz'\n",
    "reference_map_file=prefix+'reference.smap'\n",
    "print(reference_file)\n",
    "print(reference_map_file)\n",
    "\n",
    "extract_from_same_file(reference_file,reference_map_file,nquerypop_1,nsamplepop_2,train_map_file,query_map_file,train_list_file,query_list_file,train_file,query_file,pop_tr)\n",
    "print(\"-\"*100)\n",
    "sfile2=train_file\n",
    "sfile2_tsv=train_list_file\n",
    "sfile2_map=train_map_file\n",
    "\n",
    "\n",
    "qfile1=query_file\n",
    "qfile1_tsv=query_list_file\n",
    "qfile1_map=query_map_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL QUERY SET2\n",
      "../data/input/real/65k_SNP/1pop_202test.vcf.gz ../data/input/real/65k_SNP/1pop_202test.tsv ../data/input/real/65k_SNP/1pop_202test.smap\n",
      "../data/input/real/65k_SNP/\n",
      "{'EUR': 202}\n",
      "\n",
      "\n",
      "Running in command line: \n",
      "\t bcftools view -S ../data/input/real/65k_SNP/1pop_202test.tsv -Ov -o ../data/input/real/65k_SNP/1pop_202test.vcf.gz ../data/input/real/65k_SNP/reference.vcf.gz\n",
      "Done\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('REAL QUERY SET2')\n",
    "pop_qr=['EUR']\n",
    "npop=len(pop_qr)\n",
    "nquerypop_2=202\n",
    "\n",
    "query_file,query_list_file,query_map_file,prefix=naming_file(True,True,nquerypop_2,npop,nSNP,'../data/input/')\n",
    "\n",
    "reference_file=prefix+'reference.vcf.gz'\n",
    "reference_map_file=prefix+'reference.smap'\n",
    "print(query_file,query_list_file,query_map_file)\n",
    "print(prefix)\n",
    "\n",
    "extract_from_file(reference_file,reference_map_file,nquerypop_2,query_map_file,query_list_file,query_file,pop_qr)\n",
    "\n",
    "print(\"-\"*100)\n",
    "\n",
    "qfile2=query_file\n",
    "qfile2_tsv=query_list_file\n",
    "qfile2_map=query_map_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can merged the train set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Creating index for the files\n",
      "Running in command line: \n",
      "\t bcftools index -f ../data/input/artificial/65k_SNP/1pop_300train.vcf.gz\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Creating index for the files\n",
      "Running in command line: \n",
      "\t bcftools index -f ../data/input/real/65k_SNP/2pop_600train.vcf.gz\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Merging\n",
      "Running in command line: \n",
      "\t bcftools merge ../data/input/artificial/65k_SNP/1pop_300train.vcf.gz ../data/input/real/65k_SNP/2pop_600train.vcf.gz -o ../data/input/mixed_set/65k_SNP/train900_rAFR-rEAS-aEUR-.vcf.gz -O v\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_file,base1=output_name_mixed(0,nSNP,True,pop_tr,pop_ta,nsamplepop_1,'../data/input/mixed_set/')\n",
    "print(\"-\"*100)\n",
    "print('Creating index for the files')\n",
    "cmdi1='bcftools index -f '+ sfile1\n",
    "print(\"Running in command line: \\n\\t\", cmdi1)\n",
    "os.system(cmdi1)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print('Creating index for the files')\n",
    "cmdi2='bcftools index -f '+ sfile2\n",
    "print(\"Running in command line: \\n\\t\", cmdi2)\n",
    "os.system(cmdi2)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print('Merging')\n",
    "cmd=\"bcftools merge \"+sfile1 +\" \"+ sfile2+\" -o \"+ train_file+ \" -O v\"\n",
    "print(\"Running in command line: \\n\\t\", cmd)\n",
    "os.system(cmd)\n",
    "print(\"-\"*100)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging tsv and smap files too.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the TSV files into Pandas DataFrames\n",
    "df1 = pd.read_csv(sfile1_tsv, sep='\\t',header=None)\n",
    "df2 = pd.read_csv(sfile2_tsv, sep='\\t',header=None)\n",
    "\n",
    "# Concat the DataFrames\n",
    "merged_df = pd.concat([df1, df2],axis=0, ignore_index=True)\n",
    "# Save the merged DataFrame to a new TSV file\n",
    "train_list_file,_=output_name_mixed(1,nSNP,True,pop_tr,pop_ta,nsamplepop_1,'../data/input/mixed_set/')\n",
    "merged_df.to_csv(train_list_file, sep='\\t', index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the map files into Pandas DataFrames\n",
    "df1 = pd.read_csv(sfile1_map, sep='\\t',header=None)\n",
    "df2 = pd.read_csv(sfile2_map, sep='\\t',header=None)\n",
    "\n",
    "# Concat the DataFrames\n",
    "merged_df = pd.concat([df1, df2],axis=0, ignore_index=True)\n",
    "# Save the merged DataFrame to a new smap file\n",
    "train_map_file,_=output_name_mixed(2,nSNP,True,pop_tr,pop_ta,nsamplepop_1,'../data/input/mixed_set/')\n",
    "merged_df.to_csv(train_map_file, sep='\\t', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doing the same for the query set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Creating index for the files\n",
      "Running in command line: \n",
      "\t bcftools index -f ../data/input/real/65k_SNP/2pop_404test.vcf.gz\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Creating index for the files\n",
      "Running in command line: \n",
      "\t bcftools index -f ../data/input/real/65k_SNP/1pop_202test.vcf.gz\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Merging\n",
      "Running in command line: \n",
      "\t bcftools merge ../data/input/real/65k_SNP/2pop_404test.vcf.gz ../data/input/real/65k_SNP/1pop_202test.vcf.gz -o ../data/input/mixed_set/65k_SNP/test606_rAFR-rEUR-rEAS-.vcf.gz -O v\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "pop_real=['AFR','EUR','EAS']\n",
    "pop_artificial=None\n",
    "test_file,base2=output_name_mixed(0,nSNP,False,pop_real,pop_artificial,nquerypop_1,'../data/input/mixed_set/')\n",
    "\n",
    "print(\"-\"*100)\n",
    "print('Creating index for the files')\n",
    "cmdi1='bcftools index -f '+ qfile1\n",
    "print(\"Running in command line: \\n\\t\", cmdi1)\n",
    "os.system(cmdi1)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print('Creating index for the files')\n",
    "cmdi2='bcftools index -f '+ qfile2\n",
    "print(\"Running in command line: \\n\\t\", cmdi2)\n",
    "os.system(cmdi2)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print('Merging')\n",
    "cmd=\"bcftools merge \"+qfile1 +\" \"+ qfile2+\" -o \"+ test_file+ \" -O v\"\n",
    "print(\"Running in command line: \\n\\t\", cmd)\n",
    "os.system(cmd)\n",
    "print(\"-\"*100)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging tsv and smap files too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the TSV files into Pandas DataFrames\n",
    "df1 = pd.read_csv(qfile1_tsv, sep='\\t',header=None)\n",
    "df2 = pd.read_csv(qfile2_tsv, sep='\\t',header=None)\n",
    "\n",
    "# Concat the DataFrames\n",
    "merged_df = pd.concat([df1, df2],axis=0, ignore_index=True)\n",
    "# Save the merged DataFrame to a new TSV file\n",
    "test_list_file,_=output_name_mixed(1,nSNP,False,pop_real,pop_artificial,nquerypop_1,'../data/input/mixed_set/')\n",
    "merged_df.to_csv(test_list_file, sep='\\t', index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the map files into Pandas DataFrames\n",
    "df1 = pd.read_csv(qfile1_map, sep='\\t',header=None)\n",
    "df2 = pd.read_csv(qfile2_map, sep='\\t',header=None)\n",
    "\n",
    "# Concat the DataFrames\n",
    "merged_df = pd.concat([df1, df2],axis=0, ignore_index=True)\n",
    "# Save the merged DataFrame to a new smap file\n",
    "test_map_file,_=output_name_mixed(2,nSNP,False,pop_real,pop_artificial,nquerypop_1,'../data/input/mixed_set/')\n",
    "merged_df.to_csv(test_map_file, sep='\\t', index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/output_lainet/mixed/train900_rAFR-rEAS-aEUR-test606_rAFR-rEUR-rEAS-/\n"
     ]
    }
   ],
   "source": [
    "output_basename='../data/output_lainet/mixed/'+base1+base2+'/'\n",
    "print(output_basename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rm:\n",
    "    os.system('rm '+ sfile1+' '+sfile2+' '+qfile1+' '+qfile2)\n",
    "    os.system('rm '+ sfile1_tsv+' '+sfile2_tsv+' '+qfile1_tsv+' '+qfile2_tsv)\n",
    "    os.system('rm '+ sfile1_map+' '+sfile2_map+' '+qfile1_map+' '+qfile2_map)\n",
    "    os.system('rm '+ sfile1+'.csi '+sfile2+'.csi '+qfile1+'.csi '+qfile2+'.csi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/mixed_set/65k_SNP/train900_rAFR-rEAS-aEUR-.vcf.gz\n",
      "../data/input/mixed_set/65k_SNP/test606_rAFR-rEUR-rEAS-.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "print(train_file)\n",
    "print(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Merging intra continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpopulation_id=pd.read_csv('../data/input/real/PUR_sample.tsv',delimiter='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Creating index for the files\n",
      "Running in command line: \n",
      "\t bcftools index -f ../data/input/real/65k_SNP/subpop/PUR.vcf.gz\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Creating index for the files\n",
      "Running in command line: \n",
      "\t bcftools index -f ../data/input/artificial/65k_SNP/reference.vcf.gz\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Merging\n",
      "Running in command line: \n",
      "\t bcftools merge ../data/input/real/65k_SNP/subpop/PUR.vcf.gz ../data/input/artificial/65k_SNP/reference.vcf.gz -o ../data/input/mixed_set/65k_SNP/artificial+realPUR.vcf.gz -O v\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "mixed_file='../data/input/mixed_set/65k_SNP/artificial+realPUR.vcf.gz'\n",
    "print(\"-\"*100)\n",
    "file1='../data/input/real/65k_SNP/subpop/PUR.vcf.gz'\n",
    "file1_smap='../data/input/real/65k_SNP/subpop/PUR.smap'\n",
    "print('Creating index for the files')\n",
    "cmdi1='bcftools index -f '+file1\n",
    "print(\"Running in command line: \\n\\t\", cmdi1)\n",
    "os.system(cmdi1)\n",
    "\n",
    "print(\"-\"*100)\n",
    "file2='../data/input/artificial/65k_SNP/reference.vcf.gz'\n",
    "file2_smap='../data/input/artificial/65k_SNP/reference.smap'\n",
    "print('Creating index for the files')\n",
    "cmdi2='bcftools index -f '+file2\n",
    "print(\"Running in command line: \\n\\t\", cmdi2)\n",
    "os.system(cmdi2)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print('Merging')\n",
    "cmd=\"bcftools merge \"+file1 +\" \"+ file2+\" -o \"+ mixed_file+ \" -O v\"\n",
    "print(\"Running in command line: \\n\\t\", cmd)\n",
    "os.system(cmd)\n",
    "print(\"-\"*100)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the map files into Pandas DataFrames\n",
    "df1 = pd.read_csv(file1_smap, sep='\\t',header=None)\n",
    "df2 = pd.read_csv(file2_smap, sep='\\t',header=None)\n",
    "\n",
    "# Concat the DataFrames\n",
    "merged_df = pd.concat([df1, df2],axis=0, ignore_index=True)\n",
    "# Save the merged DataFrame to a new smap file\n",
    "merged_df.to_csv('../data/input/mixed_set/65k_SNP/artificial+realPUR.smap', sep='\\t', index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in command line: \n",
      "\t bcftools view -S ../data/input/real/PUR_sample.tsv -Ov -o ../data/input/real/65k_SNP/subpop/PUR.vcf.gz ../data/input/real/65k_SNP/reference.vcf.gz \n"
     ]
    }
   ],
   "source": [
    "cmd=f'bcftools view -S {subpopulation_id} -Ov -o ../data/input/real/65k_SNP/subpop/PUR.vcf.gz ../data/input/real/65k_SNP/reference.vcf.gz '\n",
    "os.system(cmd)\n",
    "print(\"Running in command line: \\n\\t\",cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RUNNING LAINET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory...\n",
      "Done\n",
      "{'MODEL': {'NETWORK': 'lainet', 'WINDOW_SIZE': 500}, 'TRAINING': {'DEVICE': 'cuda', 'OPTIM': 'Adam', 'ALPHA': 0.5, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0, 'BATCH_SIZE': 128, 'BALANCED_TYPE': 'Batch', 'ONLINE_SIMULATION_MODE': 'pre-defined', 'ONLINE_SIMULATION_REALISTIC': True, 'GENERATION_NUM_LIST': [2, 4, 16, 32, 64], 'RANDOM_TRAINVAL_SPLIT': False, 'ITER_BREAK': 10, 'NUM_EPOCHS': 20000, 'SAVE_MODEL': True}}\n"
     ]
    }
   ],
   "source": [
    "chm              = 1\n",
    "#output_basename  = output_name('lainet',btrain,nsamplepop*5,btest,nquerypop*5)\n",
    "if (os.path.isdir(output_basename)==False):\n",
    "    print('Creating directory...')\n",
    "    os.mkdir(output_basename)\n",
    "    print('Done')\n",
    "    \n",
    "# Load vcf and map files and config\n",
    "config = yaml.load(open(config_path), Loader=yaml.FullLoader)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training can takes up to 20 minutes when done on the 65k SNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 6.44 µs\n",
      "Loading vcf and .map files...\n",
      "Done loading vcf and .map files...\n",
      "A total of 899 diploid individuals where found in the vcf and .map\n",
      "A total of 3 ancestries where found: ['AFR' 'EAS' 'EUR']\n",
      "A total of 1618 sequences are used for training and 180 for validation...\n",
      "A total of 3 unique categories in train and 3 in val\n",
      "Reading genetic map from... ../data/input/real/allchrs_b37.gmap\n",
      "Information of models saved in ../data/output_lainet/mixed/train900_rAFR-rEAS-aEUR-test606_rAFR-rEUR-rEAS-/_info.npy...\n",
      "Creating Network...\n",
      "Starting training...\n",
      "Saving network in... ../data/output_lainet/mixed/train900_rAFR-rEAS-aEUR-test606_rAFR-rEUR-rEAS-/_0__network_model.pth\n",
      "Using genetic map for realistic simulation\n",
      "Validation set of shape torch.Size([330, 65535]) has been simulated...\n",
      "252812\n",
      "[     1] loss: 0.583\n",
      " accuracy is: 33.33 - Best is: 33.33 - Difference is: 0.00 - Time since best: 0\n",
      "[     3] loss: 1.114\n",
      "[     5] loss: 0.965\n",
      "[     7] loss: 0.925\n",
      "[     9] loss: 0.746\n",
      "[    11] loss: 0.682\n",
      " accuracy is: 40.18 - Best is: 40.18 - Difference is: 0.00 - Time since best: 0\n",
      "[    13] loss: 0.433\n",
      "[    15] loss: 0.652\n",
      "[    17] loss: 0.274\n",
      "[    19] loss: 0.275\n",
      "[    21] loss: 0.385\n",
      " accuracy is: 70.35 - Best is: 70.35 - Difference is: 0.00 - Time since best: 0\n",
      "[    23] loss: 0.372\n",
      "[    25] loss: 0.539\n",
      "[    27] loss: 0.469\n",
      "[    29] loss: 0.361\n",
      "[    31] loss: 0.254\n",
      " accuracy is: 77.80 - Best is: 77.80 - Difference is: 0.00 - Time since best: 0\n",
      "[    33] loss: 0.482\n",
      "[    35] loss: 0.364\n",
      "[    37] loss: 0.249\n",
      "[    39] loss: 0.424\n",
      "[    41] loss: 0.393\n",
      " accuracy is: 83.88 - Best is: 83.88 - Difference is: 0.00 - Time since best: 0\n",
      "[    43] loss: 0.315\n",
      "[    45] loss: 0.122\n",
      "[    47] loss: 0.320\n",
      "[    49] loss: 0.336\n",
      "[    51] loss: 0.106\n",
      " accuracy is: 86.88 - Best is: 86.88 - Difference is: 0.00 - Time since best: 0\n",
      "[    53] loss: 0.163\n",
      "[    55] loss: 0.122\n",
      "[    57] loss: 0.249\n",
      "[    59] loss: 0.212\n",
      "[    61] loss: 0.251\n",
      " accuracy is: 88.43 - Best is: 88.43 - Difference is: 0.00 - Time since best: 0\n",
      "[    63] loss: 0.250\n",
      "[    65] loss: 0.315\n",
      "[    67] loss: 0.136\n",
      "[    69] loss: 0.094\n",
      "[    71] loss: 0.219\n",
      " accuracy is: 89.33 - Best is: 89.33 - Difference is: 0.00 - Time since best: 0\n",
      "[    73] loss: 0.295\n",
      "[    75] loss: 0.176\n",
      "[    77] loss: 0.173\n",
      "[    79] loss: 0.229\n",
      "[    81] loss: 0.148\n",
      " accuracy is: 90.15 - Best is: 90.15 - Difference is: 0.00 - Time since best: 0\n",
      "[    83] loss: 0.278\n",
      "[    85] loss: 0.069\n",
      "[    87] loss: 0.130\n",
      "[    89] loss: 0.141\n",
      "[    91] loss: 0.134\n",
      " accuracy is: 90.76 - Best is: 90.76 - Difference is: 0.00 - Time since best: 0\n",
      "[    93] loss: 0.354\n",
      "[    95] loss: 0.213\n",
      "[    97] loss: 0.207\n",
      "[    99] loss: 0.164\n",
      "[   101] loss: 0.266\n",
      " accuracy is: 91.11 - Best is: 91.11 - Difference is: 0.00 - Time since best: 0\n",
      "[   103] loss: 0.150\n",
      "[   105] loss: 0.095\n",
      "[   107] loss: 0.193\n",
      "[   109] loss: 0.115\n",
      "[   111] loss: 0.193\n",
      " accuracy is: 91.64 - Best is: 91.64 - Difference is: 0.00 - Time since best: 0\n",
      "[   113] loss: 0.288\n",
      "[   115] loss: 0.083\n",
      "[   117] loss: 0.095\n",
      "[   119] loss: 0.147\n",
      "[   121] loss: 0.105\n",
      " accuracy is: 91.93 - Best is: 91.93 - Difference is: 0.00 - Time since best: 0\n",
      "[   123] loss: 0.092\n",
      "[   125] loss: 0.075\n",
      "[   127] loss: 0.065\n",
      "[   129] loss: 0.139\n",
      "[   131] loss: 0.176\n",
      " accuracy is: 92.04 - Best is: 92.04 - Difference is: 0.00 - Time since best: 0\n",
      "[   133] loss: 0.151\n",
      "[   135] loss: 0.165\n",
      "[   137] loss: 0.107\n",
      "[   139] loss: 0.104\n",
      "[   141] loss: 0.101\n",
      " accuracy is: 92.27 - Best is: 92.27 - Difference is: 0.00 - Time since best: 0\n",
      "[   143] loss: 0.063\n",
      "[   145] loss: 0.167\n",
      "[   147] loss: 0.160\n",
      "[   149] loss: 0.103\n",
      "[   151] loss: 0.064\n",
      " accuracy is: 92.28 - Best is: 92.28 - Difference is: 0.00 - Time since best: 0\n",
      "[   153] loss: 0.107\n",
      "[   155] loss: 0.146\n",
      "[   157] loss: 0.064\n",
      "[   159] loss: 0.045\n",
      "[   161] loss: 0.165\n",
      " accuracy is: 92.34 - Best is: 92.34 - Difference is: 0.00 - Time since best: 0\n",
      "[   163] loss: 0.165\n",
      "[   165] loss: 0.141\n",
      "[   167] loss: 0.192\n",
      "[   169] loss: 0.103\n",
      "[   171] loss: 0.115\n",
      " accuracy is: 92.43 - Best is: 92.43 - Difference is: 0.00 - Time since best: 0\n",
      "[   173] loss: 0.090\n",
      "[   175] loss: 0.172\n",
      "[   177] loss: 0.055\n",
      "[   179] loss: 0.150\n",
      "[   181] loss: 0.150\n",
      " accuracy is: 92.75 - Best is: 92.75 - Difference is: 0.00 - Time since best: 0\n",
      "[   183] loss: 0.127\n",
      "[   185] loss: 0.112\n",
      "[   187] loss: 0.212\n",
      "[   189] loss: 0.162\n",
      "[   191] loss: 0.204\n",
      " accuracy is: 92.65 - Best is: 92.75 - Difference is: 0.10 - Time since best: 1\n",
      "[   193] loss: 0.049\n",
      "[   195] loss: 0.208\n",
      "[   197] loss: 0.147\n",
      "[   199] loss: 0.105\n",
      "[   201] loss: 0.143\n",
      " accuracy is: 92.95 - Best is: 92.95 - Difference is: 0.00 - Time since best: 0\n",
      "[   203] loss: 0.037\n",
      "[   205] loss: 0.117\n",
      "[   207] loss: 0.084\n",
      "[   209] loss: 0.179\n",
      "[   211] loss: 0.047\n",
      " accuracy is: 92.99 - Best is: 92.99 - Difference is: 0.00 - Time since best: 0\n",
      "[   213] loss: 0.135\n",
      "[   215] loss: 0.128\n",
      "[   217] loss: 0.135\n",
      "[   219] loss: 0.209\n",
      "[   221] loss: 0.139\n",
      " accuracy is: 93.03 - Best is: 93.03 - Difference is: 0.00 - Time since best: 0\n",
      "[   223] loss: 0.054\n",
      "[   225] loss: 0.061\n",
      "[   227] loss: 0.147\n",
      "[   229] loss: 0.064\n",
      "[   231] loss: 0.188\n",
      " accuracy is: 93.33 - Best is: 93.33 - Difference is: 0.00 - Time since best: 0\n",
      "[   233] loss: 0.061\n",
      "[   235] loss: 0.092\n",
      "[   237] loss: 0.180\n",
      "[   239] loss: 0.061\n",
      "[   241] loss: 0.138\n",
      " accuracy is: 93.36 - Best is: 93.36 - Difference is: 0.00 - Time since best: 0\n",
      "[   243] loss: 0.098\n",
      "[   245] loss: 0.147\n",
      "[   247] loss: 0.098\n",
      "[   249] loss: 0.099\n",
      "[   251] loss: 0.155\n",
      " accuracy is: 93.48 - Best is: 93.48 - Difference is: 0.00 - Time since best: 0\n",
      "[   253] loss: 0.095\n",
      "[   255] loss: 0.052\n",
      "[   257] loss: 0.050\n",
      "[   259] loss: 0.156\n",
      "[   261] loss: 0.088\n",
      " accuracy is: 93.32 - Best is: 93.48 - Difference is: 0.17 - Time since best: 1\n",
      "[   263] loss: 0.087\n",
      "[   265] loss: 0.086\n",
      "[   267] loss: 0.149\n",
      "[   269] loss: 0.066\n",
      "[   271] loss: 0.051\n",
      " accuracy is: 93.40 - Best is: 93.48 - Difference is: 0.09 - Time since best: 2\n",
      "[   273] loss: 0.030\n",
      "[   275] loss: 0.043\n",
      "[   277] loss: 0.129\n",
      "[   279] loss: 0.121\n",
      "[   281] loss: 0.119\n",
      " accuracy is: 93.25 - Best is: 93.48 - Difference is: 0.23 - Time since best: 3\n",
      "[   283] loss: 0.193\n",
      "[   285] loss: 0.099\n",
      "[   287] loss: 0.117\n",
      "[   289] loss: 0.094\n",
      "[   291] loss: 0.129\n",
      " accuracy is: 93.61 - Best is: 93.61 - Difference is: 0.00 - Time since best: 0\n",
      "[   293] loss: 0.061\n",
      "[   295] loss: 0.173\n",
      "[   297] loss: 0.104\n",
      "[   299] loss: 0.066\n",
      "[   301] loss: 0.079\n",
      " accuracy is: 93.51 - Best is: 93.61 - Difference is: 0.10 - Time since best: 1\n",
      "[   303] loss: 0.152\n",
      "[   305] loss: 0.057\n",
      "[   307] loss: 0.141\n",
      "[   309] loss: 0.069\n",
      "[   311] loss: 0.128\n",
      " accuracy is: 93.46 - Best is: 93.61 - Difference is: 0.15 - Time since best: 2\n",
      "[   313] loss: 0.070\n",
      "[   315] loss: 0.143\n",
      "[   317] loss: 0.105\n",
      "[   319] loss: 0.122\n",
      "[   321] loss: 0.131\n",
      " accuracy is: 93.63 - Best is: 93.63 - Difference is: 0.00 - Time since best: 0\n",
      "[   323] loss: 0.071\n",
      "[   325] loss: 0.044\n",
      "[   327] loss: 0.162\n",
      "[   329] loss: 0.087\n",
      "[   331] loss: 0.061\n",
      " accuracy is: 93.81 - Best is: 93.81 - Difference is: 0.00 - Time since best: 0\n",
      "[   333] loss: 0.148\n",
      "[   335] loss: 0.066\n",
      "[   337] loss: 0.148\n",
      "[   339] loss: 0.060\n",
      "[   341] loss: 0.164\n",
      " accuracy is: 93.59 - Best is: 93.81 - Difference is: 0.22 - Time since best: 1\n",
      "[   343] loss: 0.122\n",
      "[   345] loss: 0.039\n",
      "[   347] loss: 0.053\n",
      "[   349] loss: 0.135\n",
      "[   351] loss: 0.110\n",
      " accuracy is: 93.79 - Best is: 93.81 - Difference is: 0.02 - Time since best: 2\n",
      "[   353] loss: 0.060\n",
      "[   355] loss: 0.189\n",
      "[   357] loss: 0.043\n",
      "[   359] loss: 0.095\n",
      "[   361] loss: 0.147\n",
      " accuracy is: 93.75 - Best is: 93.81 - Difference is: 0.06 - Time since best: 3\n",
      "[   363] loss: 0.058\n",
      "[   365] loss: 0.089\n",
      "[   367] loss: 0.067\n",
      "[   369] loss: 0.132\n",
      "[   371] loss: 0.072\n",
      " accuracy is: 93.59 - Best is: 93.81 - Difference is: 0.22 - Time since best: 4\n",
      "[   373] loss: 0.120\n",
      "[   375] loss: 0.039\n",
      "[   377] loss: 0.071\n",
      "[   379] loss: 0.173\n",
      "[   381] loss: 0.064\n",
      " accuracy is: 93.89 - Best is: 93.89 - Difference is: 0.00 - Time since best: 0\n",
      "[   383] loss: 0.047\n",
      "[   385] loss: 0.115\n",
      "[   387] loss: 0.029\n",
      "[   389] loss: 0.035\n",
      "[   391] loss: 0.044\n",
      " accuracy is: 93.86 - Best is: 93.89 - Difference is: 0.03 - Time since best: 1\n",
      "[   393] loss: 0.044\n",
      "[   395] loss: 0.048\n",
      "[   397] loss: 0.133\n",
      "[   399] loss: 0.025\n",
      "[   401] loss: 0.098\n",
      " accuracy is: 93.95 - Best is: 93.95 - Difference is: 0.00 - Time since best: 0\n",
      "[   403] loss: 0.113\n",
      "[   405] loss: 0.116\n",
      "[   407] loss: 0.028\n",
      "[   409] loss: 0.137\n",
      "[   411] loss: 0.105\n",
      " accuracy is: 93.69 - Best is: 93.95 - Difference is: 0.26 - Time since best: 1\n",
      "[   413] loss: 0.088\n",
      "[   415] loss: 0.097\n",
      "[   417] loss: 0.098\n",
      "[   419] loss: 0.092\n",
      "[   421] loss: 0.039\n",
      " accuracy is: 93.84 - Best is: 93.95 - Difference is: 0.11 - Time since best: 2\n",
      "[   423] loss: 0.074\n",
      "[   425] loss: 0.045\n",
      "[   427] loss: 0.098\n",
      "[   429] loss: 0.066\n",
      "[   431] loss: 0.117\n",
      " accuracy is: 93.96 - Best is: 93.96 - Difference is: 0.00 - Time since best: 0\n",
      "[   433] loss: 0.092\n",
      "[   435] loss: 0.027\n",
      "[   437] loss: 0.034\n",
      "[   439] loss: 0.069\n",
      "[   441] loss: 0.146\n",
      " accuracy is: 93.93 - Best is: 93.96 - Difference is: 0.04 - Time since best: 1\n",
      "[   443] loss: 0.105\n",
      "[   445] loss: 0.072\n",
      "[   447] loss: 0.108\n",
      "[   449] loss: 0.110\n",
      "[   451] loss: 0.081\n",
      " accuracy is: 93.71 - Best is: 93.96 - Difference is: 0.25 - Time since best: 2\n",
      "[   453] loss: 0.074\n",
      "[   455] loss: 0.049\n",
      "[   457] loss: 0.026\n",
      "[   459] loss: 0.100\n",
      "[   461] loss: 0.141\n",
      " accuracy is: 93.97 - Best is: 93.97 - Difference is: 0.00 - Time since best: 0\n",
      "[   463] loss: 0.050\n",
      "[   465] loss: 0.183\n",
      "[   467] loss: 0.052\n",
      "[   469] loss: 0.037\n",
      "[   471] loss: 0.034\n",
      " accuracy is: 93.96 - Best is: 93.97 - Difference is: 0.01 - Time since best: 1\n",
      "[   473] loss: 0.046\n",
      "[   475] loss: 0.033\n",
      "[   477] loss: 0.025\n",
      "[   479] loss: 0.024\n",
      "[   481] loss: 0.037\n",
      " accuracy is: 94.07 - Best is: 94.07 - Difference is: 0.00 - Time since best: 0\n",
      "[   483] loss: 0.037\n",
      "[   485] loss: 0.089\n",
      "[   487] loss: 0.028\n",
      "[   489] loss: 0.142\n",
      "[   491] loss: 0.073\n",
      " accuracy is: 94.01 - Best is: 94.07 - Difference is: 0.06 - Time since best: 1\n",
      "[   493] loss: 0.087\n",
      "[   495] loss: 0.061\n",
      "[   497] loss: 0.032\n",
      "[   499] loss: 0.091\n",
      "[   501] loss: 0.040\n",
      " accuracy is: 93.92 - Best is: 94.07 - Difference is: 0.15 - Time since best: 2\n",
      "[   503] loss: 0.133\n",
      "[   505] loss: 0.083\n",
      "[   507] loss: 0.080\n",
      "[   509] loss: 0.031\n",
      "[   511] loss: 0.099\n",
      " accuracy is: 93.87 - Best is: 94.07 - Difference is: 0.20 - Time since best: 3\n",
      "[   513] loss: 0.056\n",
      "[   515] loss: 0.073\n",
      "[   517] loss: 0.039\n",
      "[   519] loss: 0.035\n",
      "[   521] loss: 0.056\n",
      " accuracy is: 94.14 - Best is: 94.14 - Difference is: 0.00 - Time since best: 0\n",
      "[   523] loss: 0.064\n",
      "[   525] loss: 0.024\n",
      "[   527] loss: 0.165\n",
      "[   529] loss: 0.029\n",
      "[   531] loss: 0.034\n",
      " accuracy is: 93.86 - Best is: 94.14 - Difference is: 0.28 - Time since best: 1\n",
      "[   533] loss: 0.157\n",
      "[   535] loss: 0.088\n",
      "[   537] loss: 0.180\n",
      "[   539] loss: 0.084\n",
      "[   541] loss: 0.109\n",
      " accuracy is: 93.80 - Best is: 94.14 - Difference is: 0.34 - Time since best: 2\n",
      "[   543] loss: 0.174\n",
      "[   545] loss: 0.134\n",
      "[   547] loss: 0.097\n",
      "[   549] loss: 0.033\n",
      "[   551] loss: 0.039\n",
      " accuracy is: 93.89 - Best is: 94.14 - Difference is: 0.26 - Time since best: 3\n",
      "[   553] loss: 0.031\n",
      "[   555] loss: 0.108\n",
      "[   557] loss: 0.105\n",
      "[   559] loss: 0.132\n",
      "[   561] loss: 0.028\n",
      " accuracy is: 94.04 - Best is: 94.14 - Difference is: 0.10 - Time since best: 4\n",
      "[   563] loss: 0.110\n",
      "[   565] loss: 0.031\n",
      "[   567] loss: 0.037\n",
      "[   569] loss: 0.098\n",
      "[   571] loss: 0.046\n",
      " accuracy is: 94.06 - Best is: 94.14 - Difference is: 0.09 - Time since best: 5\n",
      "Setting learning rate to...  0.001\n",
      "[   573] loss: 0.092\n",
      "[   575] loss: 0.039\n",
      "[   577] loss: 0.074\n",
      "[   579] loss: 0.066\n",
      "[   581] loss: 0.079\n",
      " accuracy is: 94.19 - Best is: 94.19 - Difference is: 0.00 - Time since best: 0\n",
      "[   583] loss: 0.059\n",
      "[   585] loss: 0.094\n",
      "[   587] loss: 0.050\n",
      "[   589] loss: 0.104\n",
      "[   591] loss: 0.072\n",
      " accuracy is: 94.27 - Best is: 94.27 - Difference is: 0.00 - Time since best: 0\n",
      "[   593] loss: 0.031\n",
      "[   595] loss: 0.032\n",
      "[   597] loss: 0.070\n",
      "[   599] loss: 0.062\n",
      "[   601] loss: 0.100\n",
      " accuracy is: 94.30 - Best is: 94.30 - Difference is: 0.00 - Time since best: 0\n",
      "[   603] loss: 0.084\n",
      "[   605] loss: 0.032\n",
      "[   607] loss: 0.061\n",
      "[   609] loss: 0.026\n",
      "[   611] loss: 0.081\n",
      " accuracy is: 94.38 - Best is: 94.38 - Difference is: 0.00 - Time since best: 0\n",
      "[   613] loss: 0.113\n",
      "[   615] loss: 0.092\n",
      "[   617] loss: 0.064\n",
      "[   619] loss: 0.034\n",
      "[   621] loss: 0.074\n",
      " accuracy is: 94.42 - Best is: 94.42 - Difference is: 0.00 - Time since best: 0\n",
      "[   623] loss: 0.043\n",
      "[   625] loss: 0.085\n",
      "[   627] loss: 0.020\n",
      "[   629] loss: 0.054\n",
      "[   631] loss: 0.019\n",
      " accuracy is: 94.41 - Best is: 94.42 - Difference is: 0.01 - Time since best: 1\n",
      "[   633] loss: 0.024\n",
      "[   635] loss: 0.098\n",
      "[   637] loss: 0.017\n",
      "[   639] loss: 0.032\n",
      "[   641] loss: 0.032\n",
      " accuracy is: 94.40 - Best is: 94.42 - Difference is: 0.01 - Time since best: 2\n",
      "[   643] loss: 0.107\n",
      "[   645] loss: 0.048\n",
      "[   647] loss: 0.033\n",
      "[   649] loss: 0.051\n",
      "[   651] loss: 0.039\n",
      " accuracy is: 94.43 - Best is: 94.43 - Difference is: 0.00 - Time since best: 0\n",
      "[   653] loss: 0.034\n",
      "[   655] loss: 0.070\n",
      "[   657] loss: 0.108\n",
      "[   659] loss: 0.055\n",
      "[   661] loss: 0.045\n",
      " accuracy is: 94.48 - Best is: 94.48 - Difference is: 0.00 - Time since best: 0\n",
      "[   663] loss: 0.059\n",
      "[   665] loss: 0.148\n",
      "[   667] loss: 0.092\n",
      "[   669] loss: 0.055\n",
      "[   671] loss: 0.043\n",
      " accuracy is: 94.46 - Best is: 94.48 - Difference is: 0.02 - Time since best: 1\n",
      "[   673] loss: 0.110\n",
      "[   675] loss: 0.111\n",
      "[   677] loss: 0.071\n",
      "[   679] loss: 0.034\n",
      "[   681] loss: 0.083\n",
      " accuracy is: 94.43 - Best is: 94.48 - Difference is: 0.05 - Time since best: 2\n",
      "[   683] loss: 0.181\n",
      "[   685] loss: 0.036\n",
      "[   687] loss: 0.031\n",
      "[   689] loss: 0.045\n",
      "[   691] loss: 0.096\n",
      " accuracy is: 94.49 - Best is: 94.49 - Difference is: 0.00 - Time since best: 0\n",
      "[   693] loss: 0.018\n",
      "[   695] loss: 0.030\n",
      "[   697] loss: 0.127\n",
      "[   699] loss: 0.055\n",
      "[   701] loss: 0.026\n",
      " accuracy is: 94.50 - Best is: 94.50 - Difference is: 0.00 - Time since best: 0\n",
      "[   703] loss: 0.091\n",
      "[   705] loss: 0.095\n",
      "[   707] loss: 0.089\n",
      "[   709] loss: 0.017\n",
      "[   711] loss: 0.093\n",
      " accuracy is: 94.54 - Best is: 94.54 - Difference is: 0.00 - Time since best: 0\n",
      "[   713] loss: 0.095\n",
      "[   715] loss: 0.047\n",
      "[   717] loss: 0.056\n",
      "[   719] loss: 0.045\n",
      "[   721] loss: 0.078\n",
      " accuracy is: 94.54 - Best is: 94.54 - Difference is: 0.00 - Time since best: 0\n",
      "[   723] loss: 0.051\n",
      "[   725] loss: 0.041\n",
      "[   727] loss: 0.078\n",
      "[   729] loss: 0.022\n",
      "[   731] loss: 0.046\n",
      " accuracy is: 94.53 - Best is: 94.54 - Difference is: 0.01 - Time since best: 1\n",
      "[   733] loss: 0.033\n",
      "[   735] loss: 0.037\n",
      "[   737] loss: 0.081\n",
      "[   739] loss: 0.066\n",
      "[   741] loss: 0.033\n",
      " accuracy is: 94.51 - Best is: 94.54 - Difference is: 0.03 - Time since best: 2\n",
      "[   743] loss: 0.055\n",
      "[   745] loss: 0.083\n",
      "[   747] loss: 0.076\n",
      "[   749] loss: 0.023\n",
      "[   751] loss: 0.072\n",
      " accuracy is: 94.51 - Best is: 94.54 - Difference is: 0.03 - Time since best: 3\n",
      "[   753] loss: 0.112\n",
      "[   755] loss: 0.027\n",
      "[   757] loss: 0.041\n",
      "[   759] loss: 0.024\n",
      "[   761] loss: 0.042\n",
      " accuracy is: 94.51 - Best is: 94.54 - Difference is: 0.03 - Time since best: 4\n",
      "[   763] loss: 0.116\n",
      "[   765] loss: 0.108\n",
      "[   767] loss: 0.115\n",
      "[   769] loss: 0.096\n",
      "[   771] loss: 0.068\n",
      " accuracy is: 94.48 - Best is: 94.54 - Difference is: 0.07 - Time since best: 5\n",
      "Setting learning rate to...  0.0001\n",
      "[   773] loss: 0.076\n",
      "[   775] loss: 0.018\n",
      "[   777] loss: 0.091\n",
      "[   779] loss: 0.053\n",
      "[   781] loss: 0.044\n",
      " accuracy is: 94.49 - Best is: 94.54 - Difference is: 0.05 - Time since best: 6\n",
      "[   783] loss: 0.054\n",
      "[   785] loss: 0.046\n",
      "[   787] loss: 0.049\n",
      "[   789] loss: 0.089\n",
      "[   791] loss: 0.022\n",
      " accuracy is: 94.51 - Best is: 94.54 - Difference is: 0.03 - Time since best: 7\n",
      "[   793] loss: 0.045\n",
      "[   795] loss: 0.046\n",
      "[   797] loss: 0.110\n",
      "[   799] loss: 0.134\n",
      "[   801] loss: 0.073\n",
      " accuracy is: 94.51 - Best is: 94.54 - Difference is: 0.03 - Time since best: 8\n",
      "[   803] loss: 0.027\n",
      "[   805] loss: 0.018\n",
      "[   807] loss: 0.019\n",
      "[   809] loss: 0.116\n",
      "[   811] loss: 0.094\n",
      " accuracy is: 94.53 - Best is: 94.54 - Difference is: 0.01 - Time since best: 9\n",
      "[   813] loss: 0.055\n",
      "[   815] loss: 0.107\n",
      "[   817] loss: 0.080\n",
      "[   819] loss: 0.087\n",
      "[   821] loss: 0.073\n",
      " accuracy is: 94.50 - Best is: 94.54 - Difference is: 0.04 - Time since best: 10\n",
      "Finished with accuracy 0.9454299807548523 after 601.9842712879181 seconds...\n",
      "Running validation report...\n",
      "Loading... ../data/output_lainet/mixed/train900_rAFR-rEAS-aEUR-test606_rAFR-rEUR-rEAS-/_0__network_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/ifbstor1/projects/machinelearning_popgen/ter-bioinfo3/ter-bioinfo/LAI-NET/lainet/training.py:381: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_labels = torch.tensor(val_labels_).to('cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard prediction evaluation\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AFR       0.98      0.89      0.93     14540\n",
      "         EAS       0.96      0.98      0.97     14413\n",
      "         EUR       0.90      0.97      0.93     14277\n",
      "\n",
      "    accuracy                           0.95     43230\n",
      "   macro avg       0.95      0.95      0.94     43230\n",
      "weighted avg       0.95      0.95      0.94     43230\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Soft prediction evaluation\n",
      "\n",
      "        AP\n",
      "---  -----\n",
      "AFR  0.975\n",
      "EAS  0.996\n",
      "EUR  0.970\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "       AFR    EAS    EUR\n",
      "---  -----  -----  -----\n",
      "AFR  12930    283   1327\n",
      "EAS     80  14137    196\n",
      "EUR    216    270  13791\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix (Normalized)\n",
      "\n",
      "       AFR    EAS    EUR\n",
      "---  -----  -----  -----\n",
      "AFR   88.9    1.9    9.1\n",
      "EAS    0.6   98.1    1.4\n",
      "EUR    1.5    1.9   96.6\n",
      "\n",
      "\n",
      "\n",
      "Summary: \n",
      "\n",
      "Accuracy 0.9451306962757344\n",
      "Balanced Accuracy 0.9453602775722816\n",
      "Jaccard Index (micro) 0.8959694750230253\n",
      "Jaccard Index (macro) 0.8963281976113944\n",
      "Mean (macro) Average Precision 0.9804648178247315\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "## Training\n",
    "train_main(config, train_file, train_map_file, output_basename,chm,genetic_map_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n",
      "Starting inference...\n",
      "Loading best performing networks...\n",
      "Loading Meta-data...\n",
      "Loading query vcf in...../data/input/mixed_set/65k_SNP/test606_rAFR-rEUR-rEAS-.vcf.gz\n",
      "- Number of SNPs from model: 65535\n",
      "- Number of SNPs from file: 65535\n",
      "- Number of intersecting SNPs: 65535\n",
      "- Percentage of model SNPs covered by query file: 100.0%\n",
      "Running network...\n",
      "torch.Size([606, 131, 2])\n",
      "Writing .msp file...\n",
      "Done writing\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "## Inference\n",
    "net, predicted, probs, val_snps = inference_main(config, test_file, output_basename, output_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting results!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#chm</th>\n",
       "      <th>spos</th>\n",
       "      <th>epos</th>\n",
       "      <th>sgpos</th>\n",
       "      <th>egpos</th>\n",
       "      <th>n snps</th>\n",
       "      <th>NA19434.0</th>\n",
       "      <th>NA19434.1</th>\n",
       "      <th>HG02759.0</th>\n",
       "      <th>HG02759.1</th>\n",
       "      <th>...</th>\n",
       "      <th>HG00369.0</th>\n",
       "      <th>HG00369.1</th>\n",
       "      <th>NA20803.0</th>\n",
       "      <th>NA20803.1</th>\n",
       "      <th>HG00364.0</th>\n",
       "      <th>HG00364.1</th>\n",
       "      <th>HG00367.0</th>\n",
       "      <th>HG00367.1</th>\n",
       "      <th>NA12761.0</th>\n",
       "      <th>NA12761.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>534247</td>\n",
       "      <td>1213305</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1213496</td>\n",
       "      <td>1976558</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1978655</td>\n",
       "      <td>2380292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2381568</td>\n",
       "      <td>2983963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2984087</td>\n",
       "      <td>3324243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>78800843</td>\n",
       "      <td>79427502</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>79429708</td>\n",
       "      <td>80098006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>80098823</td>\n",
       "      <td>80741675</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>80741898</td>\n",
       "      <td>81317390</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>81317902</td>\n",
       "      <td>81813279</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 1218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #chm      spos      epos  sgpos  egpos  n snps  NA19434.0  NA19434.1  \\\n",
       "0       1    534247   1213305      1      1     500          0          0   \n",
       "1       1   1213496   1976558      1      1     500          0          0   \n",
       "2       1   1978655   2380292      1      1     500          0          0   \n",
       "3       1   2381568   2983963      1      1     500          0          0   \n",
       "4       1   2984087   3324243      1      1     500          0          0   \n",
       "..    ...       ...       ...    ...    ...     ...        ...        ...   \n",
       "126     1  78800843  79427502      1      1     500          0          0   \n",
       "127     1  79429708  80098006      1      1     500          0          0   \n",
       "128     1  80098823  80741675      1      1     500          0          0   \n",
       "129     1  80741898  81317390      1      1     500          0          0   \n",
       "130     1  81317902  81813279      1      1     535          0          0   \n",
       "\n",
       "     HG02759.0  HG02759.1  ...  HG00369.0  HG00369.1  NA20803.0  NA20803.1  \\\n",
       "0            0          0  ...          2          2          2          2   \n",
       "1            0          0  ...          2          2          2          2   \n",
       "2            0          0  ...          2          2          2          2   \n",
       "3            0          0  ...          2          0          2          2   \n",
       "4            0          0  ...          2          1          2          2   \n",
       "..         ...        ...  ...        ...        ...        ...        ...   \n",
       "126          0          0  ...          2          2          2          2   \n",
       "127          0          0  ...          0          2          2          2   \n",
       "128          0          0  ...          0          2          0          2   \n",
       "129          0          0  ...          0          2          2          2   \n",
       "130          0          0  ...          0          2          1          2   \n",
       "\n",
       "     HG00364.0  HG00364.1  HG00367.0  HG00367.1  NA12761.0  NA12761.1  \n",
       "0            2          2          1          2          2          2  \n",
       "1            2          2          2          2          2          2  \n",
       "2            2          2          2          2          2          2  \n",
       "3            2          2          1          1          2          2  \n",
       "4            2          2          2          2          2          2  \n",
       "..         ...        ...        ...        ...        ...        ...  \n",
       "126          2          2          2          2          2          2  \n",
       "127          2          2          0          2          2          2  \n",
       "128          2          2          0          2          1          2  \n",
       "129          2          2          0          2          2          1  \n",
       "130          2          2          0          2          1          0  \n",
       "\n",
       "[131 rows x 1218 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Plotting results!')\n",
    "output_file = output_basename+\"msp.tsv\"\n",
    "\n",
    "msp_df = pd.read_csv(output_file, sep=\"\\t\",header=1)\n",
    "msp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from lainet.postprocess import get_samples_from_msp_df\n",
    "from lainet.visualization import plot_cm, plot_chm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample Prediction\n",
      "0    NA19434        AFR\n",
      "1    HG02759        AFR\n",
      "2    HG03085        AFR\n",
      "3    HG02968        AFR\n",
      "4    HG02307        AFR\n",
      "..       ...        ...\n",
      "601  HG00369        EUR\n",
      "602  NA20803        EUR\n",
      "603  HG00364        EUR\n",
      "604  HG00367        EUR\n",
      "605  NA12761        EUR\n",
      "\n",
      "[606 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "msp_df = pd.read_csv(output_file, sep=\"\\t\",skiprows=[0])\n",
    "# reading the sample-ids\n",
    "query_samples = get_samples_from_msp_df(msp_df)\n",
    "\n",
    "# reading predictions for each of the intervals\n",
    "pred_labels = (np.array(msp_df)[:,6:].T).astype(int)\n",
    "# reducing it to only 1 of maternal/paternal prediction\n",
    "single_ind_idx = np.arange(0,len(query_samples)*2,2)\n",
    "pred_labels_single_ind = pred_labels[single_ind_idx,:]\n",
    "\n",
    "\n",
    "# predicting single ancestry by taking mode of local predictions for each individual\n",
    "y_pred = stats.mode(pred_labels_single_ind,axis=1)[0].squeeze() \n",
    "\n",
    "# get model population order from first line of file and convert from numeric predictions\n",
    "with open(output_file, \"r\") as f:\n",
    "    pop = np.array([p.split(\"=\")[0] for p in f.readline().split()[2:]])\n",
    "pred_pop = [pop[pop_ind] for pop_ind in y_pred]\n",
    "\n",
    "# put it together in dataframe\n",
    "pred_df = pd.DataFrame({\"Sample\": query_samples, \"Prediction\": pred_pop})\n",
    "print(pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample Prediction Population\n",
      "0    NA19434        AFR        AFR\n",
      "1    HG02759        AFR        AFR\n",
      "2    HG03085        AFR        AFR\n",
      "3    HG02968        AFR        AFR\n",
      "4    HG02307        AFR        AFR\n",
      "..       ...        ...        ...\n",
      "601  HG00369        EUR        EUR\n",
      "602  NA20803        EUR        EUR\n",
      "603  HG00364        EUR        EUR\n",
      "604  HG00367        EUR        EUR\n",
      "605  NA12761        EUR        EUR\n",
      "\n",
      "[606 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# adding the true labels\n",
    "\n",
    "all_sample_map_df = pd.read_csv(test_map_file, sep=\"\\t\",header=None)\n",
    "all_sample_map_df.columns = ['Sample', 'Population']\n",
    "pred_df = pred_df.merge(all_sample_map_df)\n",
    "print(pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing false prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Sample, Prediction, Population]\n",
      "Index: []\n",
      "(0, 3)\n"
     ]
    }
   ],
   "source": [
    "false_pred=pred_df[pred_df.Population!=pred_df.Prediction]\n",
    "print(false_pred)\n",
    "print(false_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for single ancestry: 100.0%\n"
     ]
    }
   ],
   "source": [
    "acc = np.mean(pred_df.Population == pred_df.Prediction)\n",
    "print(\"Accuracy for single ancestry: \", acc*100, \"%\", sep=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAIDCAYAAAAgz5sfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABpx0lEQVR4nO3dd1xT198H8E9AEBRRqYKF4mIpAk4EFbUirQrirtYBVHEL9uemrbVqHdU6asVdB65qUasERetEbUXr3gsHilZRRkAQBO7zh08uxjASQwjo5/28eD2/nHty8k16DV++59xzJYIgCCAiIiKid6Kn6wCIiIiIyjImU0REREQaYDJFREREpAEmU0REREQaYDJFREREpAEmU0REREQa+OCSqYyMDEyZMgUeHh5wcHDAzJkzi/01PD09ERISUuzjvg8cHBywePFincawY8cOODg44Pz58zqNQ1vk7+/hw4e6DkWrHj58CAcHB+zYsUPXodA7Ki3n6uLFi+Hg4KDUHhYWBi8vL9SvXx9du3YFoP3vdz8/P/j5+WltfNKOcrp40cTERKxZswaHDx9GfHw8BEFAzZo10bZtW/j5+cHCwkJrr7127Vr88ccfGDFiBGrXrg0bGxutvdb7TCqV4vnz5/jqq690HQpRkfL7RSnn7e2NhQsXKrUvWrQIS5cuhYeHB1avXp3vc9PT07Fu3TpERUXh4cOHKFeuHCwsLNCkSRMEBASo/P3y4sULtGrVChkZGdiyZQsaN26s1Gfx4sUIDQ3N9/kTJ05EYGAgAOX3WrFiRTg6OmLw4MH49NNPVYrnffTkyRP88ccfYnJUlNOnT2PWrFnw8fHBqFGjYGZmVgJRqi4kJAR//vlngccvXryI8uXL4+TJk/D398eCBQvg4+Oj1E9+Xh0/fhzVq1cH8DphjI+PF/sYGxvD1tYWAwYMQLdu3Yr9vbwPSjyZunLlCoYMGYLU1FR07twZ/fv3h56eHm7cuIHw8HDs378f+/bt09rrnzp1CvXq1cPXX3+ttdfYu3cvJBKJ1sYvDSIjI3Hr1i21k6mLFy9CX19fO0ERAKBr167w8fGBoaGhrkMpVdzd3dGjRw+ldisrq3z7S6VSWFlZ4cSJE0hISBB/0ci9evUKAwYMwK1bt9C1a1f069cPmZmZuHPnDo4cOYJGjRqpnEzt378f2dnZsLCwQERERL7JlNyUKVNgYmKi0Obk5JTvexUEAY8ePcLvv/+O4cOHY9WqVWjdurVKMb1vnj59itDQUFhZWSklUyNGjMDQoUMV2k6dOgUAmDZtGipVqiS2l6bvdwMDgwJnVwwMDDQa28HBQUzQExISEB4ejkmTJiErKwu9e/fWaOz3UYkmU6mpqRg1ahSA1+VdOzs7heNjx47FqlWrtBrD8+fPUaVKFa2+Bn+JKcrJyUFOTg4MDQ1Rvnx5XYfz3tPX1y9VCWt6ejoqVKig6zBQq1YtcaqmKGfPnsWDBw+wbt06DBs2DLt371b6w+HAgQO4cuUKZs+erZSkZWdnIzU1VeXYIiIi0LJlS9SvXx9bt27Ft99+W+Avw88//1wpsXvb2++1Q4cO8Pb2xvr16z+4ZCorKwt6eoWvaClXrhzKlVP8dZiYmAgACokUULq+3yUSicrntLqqV6+uMHaPHj3Qvn17rFu3jslUPkp0zdSWLVvw+PFjTJo0SSmRAl6ftGPHjlVo27dvH3r06AEXFxe4ublh7NixePTokUKfkJAQODs748mTJxg5ciQaN24Md3d3zJkzBzk5OQCAkydPwsHBATdv3sSpU6fg4OAgztUXNG8vf87JkyfFtvv37+Prr7+Gh4cHnJyc4OHhgeDgYDx9+lTsk9+cemJiIr7//nu0atUKzs7O6Ny5M/744w+FPvI1ICtXrhTL0U5OTujZsycuXrxY5Ocrj1cqlSI0NBStW7dG48aNERQUhJSUFGRlZWH27Nlo2bIlGjdujEmTJuHly5cKY+zYsQNfffUVWrVqBScnJ3z++edYsWIFcnNzxT5+fn44cuQI4uPjxc9RPrXw5nvYuHEjPv/8czg7O+PcuXMAFNdMCYIAPz8/uLm5KXx+OTk56N27Nzw8PJCcnFzg++3RoweGDx+u0NanTx84ODjgzJkzYtuJEyfg4OCAmJgYhb7yz8Pd3R2NGjXCqFGjxC/QNx0/fhwDBgxA48aN0bhxYwQGBuLatWsKfVQ5BwtT0DqM/NZPbNq0Cb6+vmjUqBGaNm2Krl27YsuWLeLx/M5nPz8/dOzYEbdv34a/vz8aNmyI1q1b5/vHS3x8PIYPH45GjRqhRYsWmDlzJo4dO6b0byE/8tc+ceIEZsyYIZ5rchcvXsSQIUPQtGlTuLi4oG/fvkr/XeLj4zFt2jR06tQJDRs2RLNmzTBs2DDcuHGj8A+xGEVERKBmzZpo0aIFPv30U0RERCj1efDgAQCgWbNmSsfKlSuHqlWrqvRaT58+RUxMDLy9veHj44OkpCQcP35cszfwFhsbG1StWhVxcXEq9V+zZg369u0LNzc3ODs7w9fXF+Hh4Ur9PD09ERgYiNOnT6NXr15wdnZG+/btsXPnTqW+t27dgr+/P1xcXNCmTRssXbpU4XulMKqeE/LvwIiICCxevBiffvopGjZsiIiICPTq1QsA8M0334jfWfLvorfXTDk4OGDDhg3i/35zbV5+/1azsrKwdOlSdOzYEU5OTmjZsiVGjBiBW7duqf2ZllZmZmaoW7euyufQh6ZEK1OHDh1C+fLl0alTJ5X679q1CxMnTkSDBg0wduxYJCUlYf369Thz5gz+/PNPhTlsQRAwePBgODs7Y+LEiThx4gTWrFkDa2tr9OvXDzY2Npg7dy4WLFiAChUqiL+E1ZkHf/XqFQIDA/Hy5Uv069cP1atXR0JCAo4dO4anT5/C3Nw83+dlZmYiICAAd+7cQb9+/VCzZk0cOHAA33//PZKTk5XKy3v27EF6ejr69OkDiUSC3377DcHBwThw4IBKpdvffvsN5cuXx9ChQ3H//n1s3LgRenp6MDY2xrNnzzBq1ChcvHgRO3fuhKWlpcKU56ZNm2BjY4O2bdvC0NAQMTExWLBgAVJTUzF+/HgAwPDhw5Gamor//vsP33zzTb4x7Nq1CxkZGejduzcqVqyY71/SEokEP/30E3x9ffH9999jxYoVAICVK1fiwoULWLlyZaFVxKZNm2LXrl3Izc2Fnp4eMjIycOXKFejp6eH06dNo2rQpgNdrHwwMDNCoUSOF58+aNQuVK1dGUFAQ4uPjERYWhunTp+OXX34R+0ilUkyYMAGtWrXC2LFjkZWVhT/++AP9+vXDtm3bFKZxijoHi0N4eDimT5+ODh06oH///sjOzsatW7dw7tw5fPnll4U+Ny0tDUOGDIGXlxc6duyIffv2Yd68ebC3t0fbtm0BvK4iBQQE4OnTp/D394e5uTmkUmmRSdTbZsyYAVNTU/FcAV5PmwQGBqJ+/foYNWoUypUrh127diEwMBBr1qyBm5sbAODSpUs4ffo0OnToAEtLSzx9+hRbtmyBn58fIiMjC/x3VpSsrKx8k+WKFSsqVExfvXqFqKgo8fP08fHB6NGjERsbq/DfWz49uHPnTgQHB7/z1M/u3btRrlw5eHl5wcTEBPb29oiIiEC7du3y7Z+SkqJQedTT0yuy2p6amgqZTIaaNWuqFNO6devw6aefolOnTpBIJDh48CAmT56M7Oxs9O3bV6Hvw4cP8fXXX6NXr17o3r07tm/fjpCQEDRo0ED8ozkhIQH+/v7IycnBkCFDULFiRWzdulXlSrW658SKFSugp6cHf39/CIKANm3aYPTo0fj111/Rp08f8buhoLV0c+fOxa5du/D3339j7ty5AIAmTZrk2zc3NxcjRozA8ePH0bFjR/j5+SE9PR0nT57ElStXxM9Anc9UHfmd0wYGBkoVNU1lZ2fjyZMnqFy5crGO+94QSpCrq6vQpUsXlfpmZWUJLVu2FDp16iRkZGSI7TExMYK9vb3w008/iW2TJk0S7O3thcWLFyuM0a1bN6F79+4KbT4+PsKAAQMU2rZv3y7Y29sLDx48UGiXv1ZMTIwgCIJw7do1wd7eXoiKiio09nbt2gmTJk0SH4eFhQn29vbCjh07xLbs7GwhICBAcHJyEhITEwVBEIQHDx4I9vb2QvPmzYXk5GSx74EDBwR7e3vh0KFDhb6uPN5OnToJmZmZYvvYsWMFBwcHYdCgQUJubq7Y3qdPH6F169YKY6SnpyuNO3nyZKFRo0YKYw4dOlRo166dUl/5e2jUqJHw5MkTpeP29vbCr7/+qtAWHh4u2NvbC3/88Ydw9epVoUGDBsJ3331X6HsVBEHYu3evYG9vL1y7dk0QBEH4559/BAcHByE4OFgIDAwU+/n7+wt9+vQRH8v/ewcEBCh8HrNmzRLq168vyGQyQRAE4cWLF4Krq6sQEhKi8LrJycmCu7u7MHbsWLFNnXMwP2+fM3IDBgxQOF9Hjhwp+Pj4FDpWfufzgAEDBHt7e+HPP/8U2zIzM4VWrVoJwcHBYtuaNWsEe3t7Ye/evWLby5cvhY4dOyr8WyjqtXv16iW8evVKbM/NzRU6dOig9JlnZmYK3t7eCv993vz3LhcXFyc4OTkJS5YsEdvk59r27dsLjUkQXp93Bf1s3rxZoa/839uNGzfE99+4cWNhwYIFCv3e/Fzatm0rTJgwQdiyZYvw33//FRnPm7p166bw32DZsmWCi4uLkJqaqtDv119/zTf+5s2bK73XSZMmCc+fPxeeP38uXLp0SQgMDBTs7e2F3377TaWY8vseGDhwoODl5aXQ1q5dO8He3l44deqU2Pb8+XPByclJ4Tt65syZgr29vXDhwgWxLTExUXB1dc33u/dtqp4T8u/Atm3bCi9evFDof/HixQLPF/ln+6Zp06Yptcnf85v/VuXn/KpVq5T6vnmuq/qZvv1vviDy75z8fr744guxn/wziYyMzHcc+Xt/+vSpwnv09/cXz6EbN24IEyZMEOzt7YVp06YVGduHqEQrU2lpaahYsaJKfS9fvoxnz55h+PDhMDIyEtvd3NzQoEEDHDlyBJMmTVJ4ztvzuE2bNs23PP+u5LEfP34cbdq0UXkdSHR0NMzMzNClSxexTV9fHwEBAThx4gROnDgBb29v8ViHDh0Usn/5NIJ8WqEoXbt2VZjXd3FxQWRkJHr06KHw17OLiwvOnz+PrKwssb+xsTGA11NtaWlpyMnJgaurK/744w/cuXMH9erVUymG9u3bq1xB6NWrFw4cOICffvoJFhYWMDc3V+nSY/lfl//++y/q1auH06dPw87ODu3bt8f06dORk5OD3NxcXLhwAQMGDMj3dd/8PJo1a4Z169YhPj4e9erVwz///IOUlBT4+voq/fXXrFmzfKs12j4HK1WqhP/++w8XL16Ei4uLWs81MjJSOAcNDQ3h7OyscF4dO3YM1atXx+effy62lS9fHr1798ZPP/2k8mv17t1bYQ3K9evXcffuXQwePBhJSUkKfVu2bImNGzciIyMDxsbGCv/eMzIy8PLlS1SsWBF16tTBlStX1HrPb2rXrh38/f2V2t9eJB4REQF7e3vY29sDeP3+P/vsM0RGRmLMmDFiv/Lly2Pz5s1YuXIl9uzZg127dmHXrl2QSCTo3Lkzpk6dqrRQ/G2xsbG4evWqwnS1j48PFi5ciP3796N79+5Kz/nll18Uvh/yq1b/+eefCld6GRgYYMiQIRg4cGCh8cjJvwdevXqFFy9eIDc3F25ubvj777+RmpqqUPWoXbs2XF1dxcdmZmaoU6eOwnkVHR0NZ2dnhXO2atWq6Ny5MzZt2lRkPOqeE127di2xdXr79u1D5cqV8z233vx+UeczVZWBgQFWrlyp1F7UeaeKmJgYtGjRQnwskUjQq1cvTJw4UeOx30clmkyZmJjgxYsXKvWVr4uqU6eO0jEbGxulK/4MDAyUfnlXrlwZKSkp7xitMmtrawwcOBBr165FREQEmjRpgnbt2qFLly6Fro+Ij49HrVq1lBYFy7/E316r9fHHHys8ln9xymQyleJ8+/nyf6Q1atRQahcEATKZDNWqVQPwekps4cKFuHDhAl69eqXQX50FtapOJ8jNmDEDXl5eiI2NRVhYmEpfBtWqVUPt2rXx77//ws/PD6dPn4arqytcXV2RlpaGa9euIScnBxkZGQpf9nJvf06mpqYA8j7nu3fvAkCBv4DeXtRaEufgkCFDcOLECXzxxRewtrZGy5Yt4e3tDXd39yKfa2FhoRRz5cqVFdadxMfH45NPPlGaslL3v6e1tbXCY/ln+d133xX4nOTkZBgbGyMzMxOLFi1CREQEEhISFPpocvGIubk5WrZsWWiftLQ0HD58GF988QXu378vtjdu3Bg7d+7EmTNnxCQeeJ0QTJo0CZMmTcJ///2Hf//9F+vXr4dUKoWenp44RVSQXbt2wdDQEHXq1FF4PVtbW0REROSbTDVr1qzIBejyxPHVq1e4dOkSVqxYodJCbLkDBw5g6dKluH79utKav7d/8VtaWio9/+3z/tGjRwoJulzt2rVVikfdc0Ld81UTcXFxqF27dpEL09X5TFUlkUiKPKfVGetNTk5OGDduHHJycnD79m0sW7YMqamppWoBfmlSoslU3bp1cfXqVYVKSHHR5FLVgp6b3+LIkJAQ9OzZE4cOHcLx48cxZ84cLFu2DBs3boStre07x/Cmgq7EEgRBo+cXNe6DBw8wcOBA1K5dG9988w0sLS1Rvnx5XLlyBfPmzVN5sSig+JekKk6fPo2MjAwAwM2bN1VKDgDA1dUVhw8fxqtXr3DhwgX06dMHlpaWsLS0xOnTp5GTkwM9Pb181zsU9XnI/7+8YlYUbVwunZOToxCnjY0N9u7di+joaBw/fhxHjhzB1q1b0a9fP/zwww+FjqXqL9Li8PZ/f/lnOW7cOKXL+OXk6xd//PFHbN++XVz0b2pqCj09PcyaNUvlfwPvau/evcjMzMTGjRuxceNGpeMREREKydSbatSoAV9fX3To0AGdO3fGnj17MGvWLKWrxOQEQUBkZCSysrLg6+urdPzOnTuFrsUszJuJY9u2bVGtWjX88MMPaN68Oby8vAp97unTpxEUFISmTZti2rRpMDc3h4GBAaKjo7Fu3Tql74GSOK/UPSfU/f7RNnU/0+IkX5f29sVGcvLv3bfXr1WpUkU8h1q3bg1bW1sMHjwY69ev5/6C+SjRZMrT0xPnzp3D3r17FaYb8iP/a+fu3bvw8PBQOHbnzp0C94Z5F/KKxNuVlzc3LXuTnZ0d7OzsMGzYMFy/fh09e/bEunXrMGPGjHz7W1lZ4erVq0q/GO/cuQMA+OSTT4rjbWjs4MGDyMrKwvLlyxU+3/x2Jy7OxOHZs2eYOnUqmjdvjqpVq2LBggVo06aNSn+1NmvWDOHh4YiMjFSoQDVr1gz//vsvcnNz4eDg8E5/9cmrK2ZmZsX2119BKleunG/l8dGjR0pVHmNjY3Ts2BEdO3ZEdnY2QkJCsHnzZgwfPlzjDW+trKxw8+ZNCIKg8N9Y0yt45O+hYsWKRX6We/fuRbdu3ZSqWCkpKSpfIfeuIiIiYGNjg9GjR+d7bO/evZg8eXKhF4IYGhqiXr16uH//PpKSkgqsIp0+fRrx8fEICgpSuro5MzMTkyZNwu7du1WemivMF198gbVr12LBggVo3759of9+9+3bh/Lly2PNmjUKv2DVvQjhTZaWlgqVN7l79+6p9PziOCe0tTdUzZo1ce7cuUKLBNr4TFX15u/S/Ny5cwempqZFzga0bt0aLVq0wLJly9C7d+9Ssd1JaVKiWyN8+eWXsLCwwJw5cxAbG6t0PC0tTdyJ2MnJCdWqVcPWrVuRmZkp9jl9+jQuX75crDv5ykvC//77r9iWk5OjtHVBWloasrOzFdpsbGxQvnz5QqfgPv30UyQmJkIqlYptubm5WL9+PQwNDRXmpXVJnui9+ZdeVlZWvn+hGxsbQyaTFUulYMqUKcjMzMSsWbMwdepUVKxYESEhISr9tSavEqxYsQK1a9cWf3E1a9YMp0+fxtmzZ/O9dF0VrVu3hqmpKZYvX46srCyl4/ldRfOurK2tceHCBYXXOXz4MB4/fqzQ7+31RuXKlRPX9qg6DVwYDw8PJCQk4K+//hLbMjMzlf4tqMvJyQm1atXCunXrkJaWpnT8zc9SX19f6byKjIxU2D5DG+TTdPJE9e2fL7/8EsnJyTh69CiA1+vA8jsHZDIZzp07hypVqhR6tXBERASMjIwwePBgpdfq2rUrXFxcim29nb6+PgYNGoTY2FgcOHCgyL4SiUTh319KSgq2b9/+zq/ftm1bXLp0SWGLl6SkJERGRqr0/OI4J+Rrlorj38mbOnTogJSUFKxfv17pmDxmbXymqjI3N0f9+vURGRmptOQgNjYW//zzD9q0aaNSsjl48GAkJydr/H3wPirRypSpqSmWLFmCoUOHonv37ujcuTOcnZ2hp6eHW7duITIyEpUrV8aYMWNgYGCACRMmYNKkSejXrx+6dOmCxMREbNiwARYWFhgyZEixxWVnZ4dGjRphwYIFSElJQeXKlbFnzx6lxCkmJgbTpk1Dhw4dxLVce/bswYsXLxQWkL+td+/e+OOPPzB58mRcu3YN1tbWOHDgAE6cOIFx48Zp/a9tVXl4eMDAwADDhw9Hnz59kJWVhV27duVbxndycsKePXswc+ZMNGzYEHp6evneqqAof/75Jw4ePIhp06aJ1Yvp06dj5MiR+O2335S2jXibtbU1LCwscPfuXXEfGeB1MiXfo+pdkykTExNMmzYN48ePR/fu3eHj44Nq1arh0aNHOHbsGOzs7NRalF2YL774Avv27cPgwYPRqVMnxMXFQSqVKq39CAwMhJmZGZo2bYpq1aohLi4OGzduhIODQ7HcGqlPnz7YuHEjJk6ciEuXLolbI8j/mn7Xv+719PQwc+ZMDB48GD4+PujZsydq1KiBp0+f4tSpUxAEQdzXx9PTEzt37oSJiQns7Oxw7do1REVFKVXo1HX//n3s2rVLqb1KlSpo27YtpFIpcnNz4enpme/z3d3dUaFCBURERKB9+/b4+++/sWjRIrRr1w6NGzeGiYkJ/vvvP+zcuRNPnz7F999/r1CJdnBwQPPmzbFhwwZkZWVh3759aNGihfhL/m2enp5YuHCh0pYM76pbt25YtGgRVqxYgc8++6zAfu3atcPatWsxcOBAdO3aFSkpKfjjjz9QrVo1pfVKqho8eDB27dqFwYMHw9/fHxUqVMDWrVtRo0YNldYUFsc5UbNmTVSuXBm///47KlSogIoVK8LOzk78Y+Rdde3aFREREfj5559x+fJluLq6IjMzEydPnkSnTp3QrVs3rXymwOtkLb9zGnj9mckr8iEhIRg8eDC6du2KHj16wMLCAvfv38fWrVthbGyM//3vfyq9nvyetmvWrEG/fv24fuoNJX47GWdnZ0RGRor35tu9ezcEQUCtWrXQp08fhQ0Ku3XrBmNjY6xYsQLz5s2DsbEx2rZti/Hjxxf7fZLmzZuHKVOmYOXKlTA1NUWvXr3g5uamUGJ3cHBAmzZtcPToUYSHh6N8+fKwtbXFkiVLCl2HUL58eYSFhWHBggWQSqWQyWSoVasWfvzxx1K1k2ydOnWwZMkSLFy4ED///DOqVq2Kbt26oXnz5hg0aJBC3379+uHmzZuQSqXYuHEjBEFQO5n677//MHPmTHh4eCjskdS+fXv06NFD3HSvqC+7Zs2aYffu3QqLzG1sbGBmZobExMR3TqaA1/dtMzc3x/Lly7F27VpkZmbC3NwcTZo0QZ8+fd553Le1bt0aISEhWLt2LWbNmgUnJycsX74cc+bMUejXp08fREZGIiwsDGlpaTA3N0fPnj0xYsSIYlm7UrFiRYSFhWHGjBnYsGEDKlSogG7duqFRo0YYPXq0RjvYu7q6YuvWrVi6dCk2b96MtLQ0VK9eHc7OzgqJ8HfffYdy5cqJ+605OTlh1apV+PnnnzV6bzExMUobhAJAgwYN0LZtW0RERMDc3BwNGjTI9/mGhoZo3bo1Dh8+jLS0NHz++efIyMjA8ePHsWrVKiQnJ8PExASOjo4ICQlR+E6QX3gjr5weOXIEKSkpBe4lBbz+d7Bw4ULs2rVLaTPjd1G+fHn069cPixcvxokTJwqsiLu5uWHOnDlYsWIFZs2ahRo1asDPzw+mpqb49ttv3+m1zc3NsX79esyYMUPcP+7LL7+Eubl5oRclyBXHOWFgYIC5c+di/vz5mD59Ol69eoWgoCCNkyl9fX2sWLECy5cvR2RkJA4cOIDKlSujYcOG4vpAbXymwOsrAwu6uk4qlYrJlLu7OzZv3oxly5Zh06ZNSEtLQ9WqVdG+fXsEBwerlZQOGjQIkyZNwq5du/DFF1+8c+zvG4mg7RWdRFTmrVu3DrNnz8bRo0e1eiPy91V0dDSGDRuGXbt2FXrTZSIqm0p0zRQRlX5vX/WTmZmJrVu3onbt2kyk3lFMTAx8fHyYSBG9p1iZIiIFgwcPhqWlJerVq4e0tDRERETg1q1bmDdvXr6X8BMRfeiYTBGRgnXr1mHbtm2Ij49HTk6OuL9MYRdZEBF9yJhMEREREWmgxK/mKymvnt3RdQj0njG2bK3rEIiICpSdlf9G09qird+zBtXqqtQvKioKUqkUV65cQUpKCqytrdG3b198+eWXClc3R0dH45dffsHt27dhYWGBgIAAhZ0D5FavXo1Nmzbh2bNnsLW1xYQJE1TeB5IL0ImIiKjMWbt2LQwNDTFx4kQsX74cXl5emDlzpsKWGefOncPIkSNRv359rFq1Cj169MCsWbPw+++/K4y1evVqLFy4EP379xc3gR46dCiuX7+uUizv7TQfK1NU3FiZIqLSrMQrU09vaWVcA3O7ojvh9Z0T3t5zcvbs2fj9999x+vRpGBoaYvDgwUhJSUF4eLjY5/vvv8fhw4dx9OhR6OnpISsrCy1btkTv3r3FfbtycnLg6+sLOzs7LFq0qMhYWJkiIiKiMie/zbvr16+PzMxMJCcnIysrCzExMUoXz3Tu3BkJCQm4cuUKAODs2bNITU1V2HhaX18fnTp1wtGjR1W6bdp7u2aKiIiItEgo+v6p70Imk+V7D0VTU1OYmpoW+twzZ86gSpUq+Oijj3D37l28evVK6XZM8huL37lzB87OzuK9gt/uZ2tri/T0dDx58gQ1atQo9HWZTBEREVGpERYWhtDQUKX2oKAgBAcHF/i8S5cuYceOHRg1ahT09fXF+z6+nYDJH8uPy2QyGBoawsjISKFf5cqVAQDJyclMpoiIiEgLcrVTmQoICED37t2V2gurSiUkJGD06NFwdnbGkCFDtBJXYZhMERERkdoELU3zqTKd96bU1FQMGTIERkZGWLZsGQwMDADkVZbenjKUP5YfNzU1RVZWFjIzMxVu5i6vXFWpUqXIGLgAnYiIiMqkzMxMjBgxAs+fP8dvv/2GqlWrisdq1qwJAwMD3LmjeHX/7du3AQB1677ez0q+Vkq+dkouNjYWFStWVOmepEymiIiISH25udr5UVF2dja+/vpr3LhxA6tWrYKVlZXCcUNDQ7i7uyMqKkqhPTIyEtWrV0eDBg0AAE2aNEGlSpWwZ88esU9OTg6ioqLQunVrSCSSImPhNB8RERGVOdOnT8fhw4cxYcIEvHz5EufPnxeP2drawsTEBKNGjcKAAQMwefJk+Pr64uzZswgPD8eUKVPEXdINDQ0xYsQILFy4EGZmZnB0dER4eDji4uIwf/58lWLhpp1EKuKmnURUmpX0pp1ZDy5oZVxD64Yq9fP09ER8fP7vef369XBzcwPw+nYyCxYsQGxsLMzNzfHVV1/B399f6TmrV6/Gxo0b8ezZM9jZ2al1OxkmU0QqYjJFRKVZiSdT989qZVzDWk20Mq42cc0UERERkQa4ZoqIiIjUp6WtEcoiVqaIiIiINMDKFBEREalPSzugl0VMpoiIiEht2toBvSziNB8RERGRBliZIiIiIvVxmk/EyhQRERGRBliZIiIiIvVxzZSIlSkiIiIiDbAyRUREROrLzdF1BKUGkykiIiJSH6f5RJzmIyIiItIAK1NERESkPm6NIGJlioiIiEgDrEwRERGR+rhmSsRkioiIiNTHaT4Rp/mIiIiINMDKFBEREalNELjPlBwrU0REREQaYGWKiIiI1McF6CImU0RERKQ+LkAXcZqPiIiISAOsTBEREZH6OM0nYmWKiIiISAOsTBEREZH6crk1ghyTKSIiIlIfp/lEnOYjIiIi0gArU0RERKQ+bo0gYmWKiIiISAOsTBEREZH6uGZKxMoUERERkQZYmSIiIiL1cc2UiMkUERERqY/JlIjTfEREREQaYGWKiIiI1CYI3AFdjpUpIiIiIg2wMkVERETq45opEZMpIiIiUh/3mRJxmo+IiIhIA6xMERERkfpKwTTf/fv3sXr1aly4cAG3bt1C3bp1ERkZqdDHwcGhwOdv3boVjRo1AgD4+fnh1KlTSn22bdsGZ2fnQuNgMkVERERl0q1btxAdHY2GDRsiNzcXgiAo9dm6datS2+zZs/HgwQM4OTkptDdp0gSTJk1SaLOxsSkyDiZTREREpL5SsGbK09MTXl5eAICQkBBcvnxZqY+88iQnk8lw9epV9OnTB+XKKaZBpqamSv1VwWSKiIiI1FcKpvn09NRf+r13715kZWWhS5cuxRdHsY1EREREVMpFRESgdu3acHFxUTp26tQpNG7cGM7Ozujbty9OnDih0pisTBEREZH6tDTNJ5PJIJPJlNpNTU1hamqq0diPHj3C6dOnERQUpHTM1dUVXbp0Qe3atfHs2TOEhYVh0KBBWLNmDVq0aFHouEymiIiIqNQICwtDaGioUntQUBCCg4M1GjsyMhKCIKBr165Kx0aPHq3wuH379ujSpQtCQ0OZTBEREZEWaGnNVEDAV+jevbtSu6ZVKQCQSqVo3LgxrK2ti+xraGiI9u3bY9OmTUX2LdXJVExMDNzd3XUdBhEREZWQ4pjOy8+1a9dw8+ZNTJkypdjHLpXJ1IEDB7By5UpcunQJ165d03U4RERE9LZScDWfOiIiImBgYABvb2+V+mdlZeHAgQNFbtgJ6CCZys3NxerVq7Fjxw48fvwY1tbWGD16ND777DOcOHECs2bNwu3bt2FlZYXp06eXdHhERESkilKwz1RGRgaio6MBAPHx8UhLS8PevXsBAM7OzrCysgLwOvfYvXs3PDw8ULVqVaVxTp8+jd9++w2fffYZrKys8OzZM6xfvx4PHz5UKRcp8WRq48aNmD9/PmxsbNCuXTs8fvwY//vf/zBs2DAsW7YM1atXx/Tp09G9e3elzbSIiIiI5J4/f46vv/5aoU3+ePbs2ejRowcA4OTJk3jy5AlCQkLyHad69ep49eoVFi5ciOTkZBgZGaFhw4ZYv349mjZtWmQcEiG/vde1yNfXF46OjpgzZ47Ytm7dOvz0009o1qwZVq5ciQoVKmj8Oq+e3dF4DKI3GVu21nUIREQFys6KL9HXy4iYp5VxjbuM18q42lTim3Y+fPhQaddR+ar9oUOHFksi9SH66/Ax/O/bGfisRwCatuuKzl8OxsJla/HiRbpCvxRZKqbM/gUe3n3g2r4bBn/9DW7G3lXoc/naTUydswi+fYegmWc3ePXwx6Spc/Dw0X8l+ZaoDPnkE0ts3bISzxOuIfHZdYT/sQrW1pa6DovKMJ5TVJaU+DxaRkYGKlWqpNBmYmICAPjoo49KOpz3xrrN2/FxDXN8PSwAFubVcP1mLJau2YR/z17AxhULoKenB0EQEDRpKh49foJvx4yAaSUT/LZhKwYFh2DbulDUMK8OAIg6GI3bd+PQ/4uusKlTE08TnmP5ut/RJ3A0tq1bgo8tquv43VJpYmxshP37/kBmViYGBv4PgiBg+rSJOPBXOBo39UJ6eoauQ6QyhudUGVEK1kyVFjpZlHTnzh3o6+uLj3NycsT2tzVo0KDE4irLQudOhVnVKuJj18YuMDWthO9mzMe/5y7CrWkjHD4eg3MXr2LNrz+hedOGAICGTvXRoddXWLNpG74dMwIAENj/C4WxAKCxiyM69BqI7RFRCBriX1Jvi8qAwYH9UbduTTg6tUFs7D0AwKVL13D96nEMHeKHXxat1G2AVObwnCojytjVfNqkk2Tqm2++ybd9woQJkEgkAABBECCRSLg1goreTn4AwKm+PQDgScJzAMDh4zEwr/aRmEgBQCWTivi0lRsOH4sRk6n8xrKsYYGqVSrjybPnxR88lWm+nT/HyZNnxV96AHDv3gP888+/6OL7OX/xkdp4TlFZU+LJ1Pr160v6JT9Yp89dAgDUrfV6p9fYO/dhW7eWUj/burUQsfcg0tMzUKGCcb5jxd6LQ2JSsjgWkZyjoz0ipH8ptV+5ehO9enbWQURU1vGcKiM4zScq8WSqefPmJf2SH6QnCc+w5LcNcG/WWKxQpaSmwfJjC6W+pv+/hi0lNS3fZCo7Owc//rwYZlUqo0fnDtoNnMocM7MqSE5OVmpPSkpG1aqVSz4gKvN4TlFZU+JX823btg1JSUkl/bIflPT0DARPmg59fX3M+G6MxuPNXLAU5y9dw+wpE1DZtFLRTyAiovdfbq52fsqgEk+mvv/+ezx48EB8nJubCw8PD9y4caOkQ3kvvczMxKiJU/Hw0WOsWDhDvEIPAEwrmUCWmqb0HFlqKgCgciUTpWMLl63BtogoTP92DFq5Fb1xGX14kpJSUKVKFaX2qlWrICkppeQDojKP51QZwWRKVOLJ1Nt7hAqCgGfPniE7O7ukQ3nvvMrOxpjvZuLK9VtYNm867G3qKBy3qVMTsXfvKz0v9m4cPrYwV5riWxH2O1ZvDMc3/xuOLh3bazV2KruuXr2JBo72Su2O9e1w7dpNHUREZR3PKSprSjyZIu3Izc1FyLS5OHXmAn796Xs0dKqv1KedhzueJDzHv+cuim1pL17gyN8n0c7DTaHvxvBdWLxyPUYPDUC/Xl3eHopIJI38C25uTVCnTk2xrVatT9CypSukkft1GBmVVTynyghB0M5PGcRk6j0xY/4S7Dt0DAF9e8DYyAgXLl8Tf/57mgDgdTLV0Kk+Qqb/jD0HjuDvk2cQNGkaBEHAwP5fiGPtOXAEcxatgId7M7g1bagwVn6VLfqw/bZ6E+7de4Ad29fA1/dzdO78GXZsX4sHDx5h5aoNug6PyiCeU1TWlPi9+erVqwd/f398/PHHAF5XVObNm4eAgABYWCheaSaRSPDVV1+90+t8aPfm+7xnAB799zTfYyMG9ceowAEAXt9O5ufQVTh09ASysl6hoVM9TAgeinp2dcX+382Yj11RB/Idq1ljZ6wLnVv8b6AM4L35CmZtbYn586bCq30bSCQSHDp8HGPH/YD79x/qOjQqo3hOqa/E7833+w9aGde47zStjKtNOkmmVKXJpp0fWjJF2sdkiohKMyZTulPi+0xdv35d5b4XL14suhMRERGVvDJ65Z026OR2MoWJi4tDREQEpFIp4uLieDsZIiKi0og7oItKRTKVmJiI3bt3QyqV4tKl17dAad68OUaMGKHjyIiIiIgKp7NkKj09Hfv374dUKkVMTAyys7NRu3ZtAMDSpUvRrl07XYVGREREReE0n6jEk6kjR45AKpXi0KFDyMjIgIWFBfz9/dGlSxdYWlqiefPmMDFR3ombiIiIqDQq8WRq+PDhkEgkaNmyJYYOHYrmzZtDIpEAAFL//7YmREREVMqV0Q02taHEk6lGjRrh/PnzOHHiBDIzM+Hr64sOHTrkex8mIiIiKqU4zScq8WRqy5YtePDgAaRSKSIjI/HDDz/gxx9/hIeHB9q1aydWqYiIiIjKghLftPNtly9fhlQqxZ49e5CQ8Pq2J56envDz80OLFi3eeVxu2knFjZt2ElFpVuKbdq4er5VxjQPnaWVcbdJ5MiWXm5uLEydOIDIyEn/99RdevHiBjz/+GIcPH36n8ZhMUXFjMkVEpRmTKd0pFftMAYCenh5atWqFVq1aYerUqTh48CCkUqmuwyIiIqL8cNNOUalJpt5Uvnx5eHt7w9vbW9ehEBERUT6E3FIxsVUq6Ok6ACIiIqKyrFRWpoiIiKiU49YIIlamiIiIiDTAyhQRERGpjwvQRaxMEREREWmAlSkiIiJSH6/mEzGZIiIiIvVxAbqI03xEREREGmBlioiIiNTHypSIlSkiIiIiDbAyRUREROoTuABdjskUERERqY/TfCJO8xERERFpgJUpIiIiUh/3mRKxMkVERESkAVamiIiISH28N5+IlSkiIiJSX66gnR813L9/H1OmTEHXrl3h6OiIzp07K/UJCQmBg4OD0s/evXuV+q5evRqenp5wcXFBjx49cOLECZXiYGWKiIiIyqRbt24hOjoaDRs2RG5uLoQCtmuwtrbGvHnzFNpq166t8Hj16tVYuHAhxowZA0dHR4SHh2Po0KEIDw9HvXr1Co2DyRQRERGpTSgFWyN4enrCy8sLwOsK1OXLl/PtZ2RkhEaNGhU4TlZWFpYtWwZ/f38EBgYCAJo3bw5fX18sW7YMixYtKjQOTvMRERFRmaSnVzxpzNmzZ5GamgofHx+xTV9fH506dcLRo0cLrHjJsTJFRERE6tPS1ggymQwymUyp3dTUFKampu80ZlxcHJo1a4aMjAzY2dlh6NCh8Pb2Fo/HxsYCAGxsbBSeZ2tri/T0dDx58gQ1atQocHwmU0RERFRqhIWFITQ0VKk9KCgIwcHBao9Xv359ODs7w9bWFqmpqdi2bRvGjBmDly9fokePHgBeJ3CGhoYwMjJSeG7lypUBAMnJyUymiIiIqJhpaWuEgIAAdO/eXan9XatSAQEBCo+9vLzg7++PxYsXi8mUpphMERERkfq0NM2nyXSeqjp27Ihp06YhMTERZmZmMDU1RVZWFjIzM1G+fHmxX0pKCgCgSpUqhY7HBehERET0QZOvlZKvnZKLjY1FxYoVYWFhUejzmUwRERGR+nJztfOjZYIgICoqClZWVjAzMwMANGnSBJUqVcKePXvEfjk5OYiKikLr1q0hkUgKHZPTfERERFQmZWRkIDo6GgAQHx+PtLQ0cWdzZ2dnAK/3n/Lx8UGtWrUgk8kQHh6OU6dOYe7cueI4hoaGGDFiBBYuXAgzMzNx0864uDjMnz+/yDiYTBEREZH6tLRmSh3Pnz/H119/rdAmfzx79mx4enrCxMQEy5Ytw/Pnz2FgYABHR0csW7YMnp6eCs+Tb9a5YcMGPHv2DHZ2dli5cmWRu58DgEQoaieqMurVszu6DoHeM8aWrXUdAhFRgbKz4kv09V5831sr41b88Q+tjKtNXDNFREREpAFO8xEREZH6SsE0X2nByhQRERGRBliZIiIiIrUJJbCNQVnBZIqIiIjUx2k+Eaf5iIiIiDTAyhQRERGpj5UpEStTRERERBpgZYqIiIjUJ3ABuhwrU0REREQaYGWKiIiI1Mc1UyImU0RERKQ2gcmUiNN8RERERBpgZYqIiIjUx8qUiJUpIiIiIg2wMkVERETq4735REymiIiISH2c5hNxmo+IiIhIA6xMERERkfpYmRKxMkVERESkAVamiIiISG2CwMqUHJMpIiIiUh+n+USc5iMiIiLSACtTREREpD5WpkSsTBERERFp4L2tTBlbttZ1CPSeyXh0TNch0HuE31FU1gmsTIlYmSIiIiLSwHtbmSIiIiItYmVKxGSKiIiI1Mf7HIs4zUdERESkAVamiIiISG1cgJ6HlSkiIiIiDbAyRUREROpjZUrEZIqIiIjUxwXoIk7zEREREWmAlSkiIiJSGxeg52FlioiIiEgDrEwRERGR+rhmSsRkioiIiNTGab48nOYjIiIi0gArU0RERKQ+TvOJmEwRERFRmXT//n2sXr0aFy5cwK1bt1C3bl1ERkaKx3NycrBmzRpER0fj9u3byMnJgb29PYKCgtCiRQuFsTw9PREfH6/0GidOnICZmVmhcTCZIiIiIrUJpaAydevWLURHR6Nhw4bIzc2FICiu43r58iVWrFiBbt26ITAwEOXKlcOff/6JgQMHYtmyZWjXrp1C/w4dOmDQoEEKbaampkXGwWSKiIiIyiRPT094eXkBAEJCQnD58mWF40ZGRjh48CAqV64stnl4eODevXtYs2aNUjJVrVo1NGrUSO04uACdiIiI1JerpR816OkVnsbo6+srJFIAIJFIUK9ePTx9+lS9FysEK1NERESkNm1N88lkMshkMqV2U1NTlabcipKbm4tz587BxsZG6ZhUKkV4eDj09fXRtGlTjB07Fg0aNChyTCZTREREVGqEhYUhNDRUqT0oKAjBwcEaj79hwwbcvXsXP/74o0K7p6cnXFxcYGlpifj4eKxcuRL9+/fHtm3bYGtrW+iYTKaIiIhIfVqqTAUEBKB79+5K7cVRlTp16hR+/vlnDBo0CM2aNVM4NnnyZPF/N2vWDG3atEGnTp2wcuVKzJ07t9BxmUwRERFRqVFc03lvu379OkaOHAkvLy9MmDChyP5Vq1aFu7s7rly5UmRfJlNERESkttKwNYKq4uLiMHjwYDg6OmLu3LmQSCTFOj6TKSIiIlJbWUmmEhISMGjQIFSrVg1Lly6FoaGhSs9LTEzEiRMnlLZPyA+TKSIiIiqTMjIyEB0dDQCIj49HWloa9u7dCwBwdnbGRx99hMGDB+P58+cICQnB7du3FZ4v31MqMjIShw8fRps2bWBhYYH4+HisWrUKWVlZGDJkSJFxSIS3twt9T5QztNJ1CPSeyXh0TNch0HvE2LK1rkOg90x2lvKtULTpSbu2WhnX4nC0yn0fPnyI9u3b53ts9uzZaN68eYHHAeDGjRsAgPPnz2P+/Pm4ffs2ZDIZTExM0Lx5cwQHB8Pe3r7IOJhMEamIyRQVJyZTVNw+xGSqtOA0HxEREalPKN5F3GUZkykiIiJSW1lZgF4SeG8+IiIiIg2wMkVERERqE3I5zSfHyhQRERGRBliZIiIiIrVxzVQeJlNERESkNoFX84k4zUdERESkAVamiIiISG2c5svDyhQRERGRBliZIiIiIrVxa4Q8rEwRERERaYCVKSIiIlKbIOg6gtKDyRQRERGpjdN8eTjNR0RERKQBVqaIiIhIbaxM5WFlioiIiEgDrEwRERGR2rgAPQ+TKSIiIlIbp/nycJqPiIiISAOsTBEREZHaBIGVKTlWpoiIiIg0wMoUERERqU3I1XUEpQeTKSIiIlJbLqf5RJzmIyIiItIAK1NERESkNi5Az8PKFBEREZEGWJkiIiIitXHTzjxqVaaysrIQHh6OcePGYeDAgbh69SoAQCaTYefOnfjvv/+0EiQRERFRaaVyZSopKQkBAQG4efMmqlWrhufPnyMlJQUAYGJigkWLFuHWrVuYMGGC1oIlIiKi0oH35sujcmVq3rx5ePToETZv3oyIiAgIb3yKenp6+Pzzz3H06FGtBElERESli5Ar0cpPWaRyMnX48GH4+fmhSZMmkEiU32ytWrXw+PHjYg2OiIiIqLRTeZovLS0NH3/8cYHHs7KykJOTUyxBERERUenGTTvzqFyZqlWrFi5fvlzg8ePHj8POzq5YgiIiIiIqK1ROpnr37o0dO3YorJeSSCTIyMjAvHnz8Pfff+PLL79U+YXv37+PQ4cOKbUfO3YMPXr0QKNGjeDl5YWNGzeqPCYRERGVDEGQaOWnLFJ5ms/Pzw+3bt3CxIkTUbFiRQDAmDFjIJPJkJOTg/79+6NHjx4qv3BoaCgeP34MT09Pse3GjRsYOXIkDA0N0aZNG9y7dw8zZ85EjRo14OXlpcbbIiIiIm3i1Xx51Nq0c/r06ejWrRuioqJw//595ObmombNmvD29kazZs3UeuELFy4gICBAoW3jxo3Izc3Fpk2bUK9ePQiCgBEjRiAsLIzJFBEREZVKau+A3qRJEzRp0kTjF05ISEDdunUV2o4cOQIXFxfUq1cPwOtpxF69emHq1Kkavx7l+eQTS8yfNxVe7VtDIpHg4KFjGDvuBzx48EjXoVEp8tfhY9izPxpXrt9CYlIyPraojvZtW2Gofx9UrFhB7JciS8X8Jatx6NgJZGZmoqFTfUwcPRT2NnXEPpev3cS2iCicOX8Zj58koEoVUzR1aYDgoQH4xLKGLt4elXL8nir9uAA9j87uzVe+fHlkZWWJj+Pj45GQkABXV1eFflWqVEFqampJh/feMjY2wv59f8DBwQYDA/+HgIGjYWtbBwf+CkeFCsa6Do9KkXWbt0NfXw9fDwvA8gU/ok93H/yxczeG/O9b5ObmAgAEQUDQpKn4++RpfDtmBBbOnIzs7GwMCg7Bf08TxLGiDkbj9t049P+iK5bNn44xwwfi6s1Y9AkcjcdPEgoKgT5Q/J6iskblypSnp2e++0u9SSKR4MCBAyqNZ2dnh71796Jt27YAgH379kEikaB169YK/R49eoRq1aqpGiYVYXBgf9StWxOOTm0QG3sPAHDp0jVcv3ocQ4f44ZdFK3UbIJUaoXOnwqxqFfGxa2MXmJpWwncz5uPfcxfh1rQRDh+PwbmLV7Hm15/QvGlDAEBDp/ro0OsrrNm0Dd+OGQEACOz/hcJYANDYxREdeg3E9ogoBA3xL6m3RWUAv6fKhrK6WFwbVE6mmjdvrpRM5eTk4NGjRzh79izs7Ozg6Oio8gsPHjwYw4YNw+PHj1GtWjXs27cPDRo0UKpMHT58GA0aNFB5XCqcb+fPcfLkWfELCgDu3XuAf/75F118P+eXFIneTn4AwKm+PQDgScJzAMDh4zEwr/aRmEgBQCWTivi0lRsOH4sRk6n8xrKsYYGqVSrjybPnxR88lWn8niobuAA9j8rJ1E8//VTgsevXryMwMBC+vr4qv3Dbtm2xYMECbNy4EdevX4e3tzfGjh2r0Of58+e4d+8ehgwZovK4VDhHR3tESP9Sar9y9SZ69eysg4ioLDl97hIAoG4tawBA7J37sK1bS6mfbd1aiNh7EOnpGQVOy8Tei0NiUrI4FpEcv6dIVffv38fq1atx4cIF3Lp1C3Xr1kVkZKRSv+joaPzyyy+4ffs2LCwsEBAQAD8/P6V+q1evxqZNm/Ds2TPY2tpiwoQJaNGiRZFxqL0APT/16tVDnz59MG/ePOzYsUPl53l7e8Pb27vA4x999BH+/PPP4giR/p+ZWRUkJycrtSclJaNq1colHxCVGU8SnmHJbxvg3qyxWKFKSU2D5ccWSn1NK1USj+eXTGVn5+DHnxfDrEpl9OjcQbuBU5nD76myoTQsQL916xaio6PRsGFD5ObmKtw3WO7cuXMYOXIkunbtikmTJuHs2bOYNWsWypUrh759+4r9Vq9ejYULF2LMmDFwdHREeHg4hg4divDwcPHCuIIU2wL0jz76CLdv3y6u4QC8XpS+YsUKdO7Mv0SIdCk9PQPBk6ZDX18fM74bo/F4MxcsxflL1zB7ygRUNq1UDBES0YfI09MT0dHR+PXXXwtcErRkyRI4Ojpi1qxZcHd3x8iRI9GrVy8sWbJEvJgmKysLy5Ytg7+/PwIDA9GiRQv8/PPPsLa2xrJly4qMo1iSqaSkJGzfvh01amh+iXNycjJ+//139OvXD15eXvjll19gZmZWDFESACQlpaBKlSpK7VWrVkFSUkrJB0Sl3svMTIyaOBUPHz3GioUzUMO8unjMtJIJZKlpSs+R/f8VuJUrmSgdW7hsDbZFRGH6t2PQyq2p9gKnMovfU2VDadgBXU+v8DQmKysLMTExSrNgnTt3RkJCAq5cuQIAOHv2LFJTU+Hj4yP20dfXR6dOnXD06NF8K15vUnmaz98//6ttUlNTcefOHbx69Qpz585VdTgFmZmZOHjwICIiInD8+HFkZ2dDIpGgX79+GDRoEKysrN5pXFJ29epNNHC0V2p3rG+Ha9du6iAiKs1eZWdjzHczceX6Laz6ZabC3lEAYFOnJk6cOqv0vNi7cfjYwlxpim9F2O9YvTEc344ZgS4d22s1diq7+D31YZPJZJDJZErtpqamMDU1VWusuLg4vHr1CjY2Ngrt8nsJ37lzB87OzoiNjQUApX62trZIT0/HkydPCi0YqVyZEgRB6QcAPvnkE/Tv3x9SqVSt6ThBEHD8+HFMmjQJLVu2xNixY3H58mX069cPa9euhSAI6NixIxOpYiaN/Atubk1Qp05Nsa1WrU/QsqUrpJH7dRgZlTa5ubkImTYXp85cwK8/fY+GTvWV+rTzcMeThOf499xFsS3txQsc+fsk2nm4KfTdGL4Li1eux+ihAejXq4vW46eyi99TZUOuINHKT1hYGNq3b6/0ExYWpnaMKSmvK5lvJ2Hyx/LjMpkMhoaGMDIyUuhXufLrNXr5reF7k8qVqQ0bNqjaVSWtW7fG8+fPUaFCBXh5ecHX1xctW7aEnp4eN+nUot9Wb8LIEV9hx/Y1mPLDXAiCgGlTJ+LBg0dYuap4/xtT2TZj/hLsO3QMQwO+hLGRES5cviYeszCvhhrm1dHOwx0NneojZPrPGDcqEJUrVcKqDVshCAIG9v9C7L/nwBHMWbQCHu7N4Na0ocJYJhUrwKaO8hWB9OHi91TZoK2dEQICAtC9e3eldnWrUiVJpWQqIyMDw4YNQ9euXdGzZ89ieeFnz54BeF1qa968ORo1alTk3CdpLj09A5916I3586YibO2vkEgkOHT4OMaO+wEvXqTrOjwqRY7HnAYArAzbgpVhWxSOjRjUH6MCB0BPTw9Lf56Gn0NXYca8JcjKeoWGTvWwZvEcfGyRt7bq75gzr6vRMafFceWaNXbGutB3WyJA7yd+T33Y3mU6ryDyytLb04byx/LjpqamyMrKQmZmJsqXLy/2k1eu8lvD9yaVkiljY2NcuXKlWK+q27t3L6RSKSIjI/Hdd99h+vTpaNOmDXx9fYvl3n9UsAcPHqF3n6G6DoNKub+2q1ZSr2xaCTO+HQt8W3CfmZPHYebkccUUGX0I+D1V+pWGrRGKUrNmTRgYGODOnTto06aN2C7ffUB+j2D5WqnY2FiFDchjY2NRsWJFWFgobwHzJpVLQa6urjh9+nTRHVVUu3ZtBAcHY9++fdiyZQt69eqFM2fO4Ouvv8Znn30GiUQiLggjIiIiUpehoSHc3d0RFRWl0B4ZGYnq1auL2yk0adIElSpVwp49e8Q+OTk5iIqKQuvWrYu+nZ5Q1PV+/y8+Ph6DBg2Cp6cn+vXrBysrq2KflsvJycHx48cRERGBQ4cO4eXLl6hRowa6dOmCMWPU29umnCEXrlPxynh0TNch0HvE2LJ10Z2I1JCdFV+ir/d3jV5aGbfVf9tU7puRkYHo6GgAwKZNm/DgwQOEhIQAAJydnWFlZYVz585hwIAB6N69O3x9fXH27Fn8+uuvmDJlSr6bdo4dO1bctPOvv/5SadPOQpOpnTt3olmzZvjkk0/g4uICQRCQnZ0N4PXeDuXKKc4SSiQSnD9/XuUPoTAZGRn466+/IJVKERMTg8uXL6v1fCZTVNyYTFFxYjJFxa2kk6ljWkqmWquRTD18+BDt2+e/zcrs2bPRo0cPAK9vJ7NgwQLExsbC3NwcX331Vb5bPq1evRobN27Es2fPYGdnp/LtZApNpurXr4+5c+fC19cXISEhRZa55MGrYsGCBejfv7/CPGR0dDSaNm0KE5O8jf7i4uIwZcoUrFu3TqVx5ZhMUXFjMkXFickUFbcPMZkqLQpdgP5mnlXYjY7fxapVq+Dl5SUmUzk5ORg+fDi2bdumsCV8UlISTp48WayvTURERJoRUPoXoJcUne1FkF9BTMXlW0RERESlRpFbI6gytUdEREQfllzWP0RFJlPffPMNvvvuO5UGK84F6ERERFR65XKaT1RkMtWwYUNYW1uXRCwAWAkjIiKisqXIZKpPnz7w9fXVyosHBAQoJU/9+/dXaOM6KiIiotKHC9DzqHyj4+IWFBSkq5cmIiIiKjZMpoiIiEhtuboOoBTR2dYIRERERO+DQitT169fL6k4iIiIqAzhmqk8OpvmIyIiorKL03x5OM1HREREpAFWpoiIiEhtrEzlYWWKiIiISAOsTBEREZHauAA9D5MpIiIiUlsucykRp/mIiIiINMDKFBEREaktl9N8IlamiIiIiDTAyhQRERGpTdB1AKUIkykiIiJSG/eZysNpPiIiIiINsDJFREREasuVcAG6HCtTRERERBpgZYqIiIjUxgXoeViZIiIiItIAK1NERESkNl7Nl4fJFBEREamN9+bLw2k+IiIiIg2wMkVERERq47358rAyRURERKQBVqaIiIhIbdwaIQ+TKSIiIlIbF6Dn4TQfERERkQZYmSIiIiK1cZ+pPKxMEREREWmAlSkiIiJSGxeg52EyRURERGrjAvQ8nOYjIiIi0gArU0RERKQ2LkDPw8oUERERkQZYmSIiIiK16boy5efnh1OnTuV7bNy4cRg6dCgWL16M0NBQpeMTJ05EYGBgscXCZIqIiIjKnB9++AFpaWkKbbt27cLmzZvRpk0bsc3IyAhhYWEK/SwtLYs1FiZTREREpDZBx1fz2draKrXNmDED9vb2qFevntimp6eHRo0aaTUWrpkiIiIiteVq6edd3bt3D5cuXUKXLl00GOXdsDJFREREpYZMJoNMJlNqNzU1hampaYHPi4iIgJ6eHnx9fRXaX758iRYtWiAlJQU1a9aEn58f+vfvX6wxM5kiIiIitWlrAXpYWFi+i8aDgoIQHBxc4POkUilcXV1Ro0YNsa1mzZoYP348HB0dkZWVhb1792L69OlITEwsdCx1MZkiIiKiUiMgIADdu3dXai+sKnX+/HnExcVh2LBhCu1du3ZVeNy2bVsAwKpVqxAYGIgKFSoUQ8RMpoiIiOgdaOvefEVN5+UnIiIC5cuXR8eOHYvs27FjR+zYsQO3b9+Gi4vLu4apgMkUERERqa203JsvOzsbe/bsQbt27WBiYqKTGHg1HxEREZVZx48fR1JSkspX8e3ZswdGRkaws7MrthhYmSIiIiK16XoHdLmIiAhUqVJFYaNOuR49eqBbt26oU6cOXr16hT179kAqleJ///sfjI2Niy0GJlNERERUJr148QKHDh1Ct27dYGBgoHS8Zs2aCAsLQ0JCAoDXG33OmjULPXv2LNY4mEwRERGR2kpDZapixYo4f/58gcd/+eWXEomDyRQRERGpTVtX85VFXIBOREREpAFWpoiIiEhtpWVrhNKAlSkiIiIiDbAyRURERGorDQvQSwtWpoiIiIg0wMoUERERqY1X8+VhMkVERERqy2U6JWIyRaQiY8vWug6B3iMZj47pOgQiKiZMpoiIiEhtXICehwvQiYiIiDTAyhQRERGpjSum8jCZIiIiIrVxmi8Pp/mIiIiINMDKFBEREamN9+bLw8oUERERkQZYmSIiIiK1cdPOPEymiIiISG1MpfJwmo+IiIhIA6xMERERkdq4NUIeVqaIiIiINMDKFBEREamNC9DzMJkiIiIitTGVysNpPiIiIiINsDJFREREauMC9DysTBERERFpgJUpIiIiUhsXoOdhZYqIiIhIA6xMERERkdpYl8rDZIqIiIjUxgXoeTjNR0RERKQBVqaIiIhIbQIn+kSsTBERERFpgJUpIiIiUhvXTOVhMkVERERq4z5TeTjNR0RERKQBVqaIiIhIbaxL5WFlioiIiEgDrEwRERGR2rhmKg+TKSIiIlIbr+bLw2k+IiIiKnN27NgBBwcHpZ/p06cr9IuOjkb37t3h7OwMLy8vbNiwodhjYWWKiIiI1FZadkD/7bffUKlSJfFxtWrVxP997tw5jBw5El27dsWkSZNw9uxZzJo1C+XKlUPfvn2LLQYmU0RERFRmNWjQAGZmZvkeW7JkCRwdHTFr1iwAgLu7Ox4/fowlS5agT58+0NMrngk6TvMRERGR2nK19FNcsrKyEBMTA29vb4X2zp07IyEhAVeuXCm212IyRURERGWWr68v6tevD09PT4SGhiI7OxsAEBcXh1evXsHGxkahv52dHQDgzp07xRYDp/mIiIhIbdpaMyWTySCTyZTaTU1NYWpqKj6uXr06goOD4eLiAn19fRw9ehRLly7Fw4cP8dNPPyElJUV83tvjABCPFwcmU0RERKQ2bW2NEBYWhtDQUKX2oKAgBAcHi49bt26N1q1bi49btWqFSpUqYfHixRg5cqSWossfkykiIiIqNQICAtC9e3el9rcrTPnp1KkTFi9ejCtXrojTeW9XueSPK1euXAzRvsZkioiIiNSWK2hnmu/t6bx3VbNmTRgYGODOnTto06aN2H779m0AQN26dTV+DTkuQCciIqL3wu7duyGRSODk5ARDQ0O4u7sjKipKoU9kZCSqV6+OBg0aFNvrsjJFREREatP1lp2BgYFwc3ODvb09JBIJjh07hs2bN6NXr16wtrYGAIwaNQoDBgzA5MmT4evri7NnzyI8PBxTpkwptj2mACZTRERE9A50faPjunXrYvv27Xjy5Amys7NRu3ZtjB8/HgEBAWKfxo0bY+nSpViwYAF27twJc3NzfPPNN8W6+zkASARBS5OeOlbO0ErXIRARFSjj0TFdh0DvGYNqxbcGSBX9aikvEi8Om+//qZVxtYmVKSIiIlJbabk3X2nABehEREREGmBlioiIiNSmrU07yyImU0RERKQ2XS9AL004zUdERESkAVamiIiISG1cgJ6HlSkiIiIiDbAyRURERGrjAvQ8rEwRERERaYCVKSIiIlLbe3oDlXfCZIqIiIjUxq0R8nCaj4iIiEgDrEwRERGR2rgAPQ8rU0REREQaYGWKiIiI1MZNO/OUiWQqLS0NJiYmug6DiIiI/h8XoOcp1dN8z549w7x58/Dpp5/qOhQiIiKifOm0MnX+/Hn8+eefePz4MWrWrAl/f3/UrFkTiYmJCA0Nxfbt25GdnQ1vb29dhklERERv4T5TeXSWTEVHR2PEiBEQBAFmZmb4559/EBkZifnz52P8+PFISUmBj48PRo4ciTp16ugqTCIiIqJC6SyZWrFiBRo0aIAlS5bA3Nwc6enp+P777zFs2DBUr14dq1atgpOTk67CIyIiokJwa4Q8OlszdefOHQwbNgzm5uYAgAoVKmD8+PHIzs7GuHHjmEgRERGVYoKW/q8s0lllKjk5WUyk5OSPa9WqpYuQPhiffGKJ+fOmwqt9a0gkEhw8dAxjx/2ABw8e6To0KqN4TpEq/jp8DHv2R+PK9VtITErGxxbV0b5tKwz174OKFSuI/VJkqZi/ZDUOHTuBzMxMNHSqj4mjh8LeJm/Jx+VrN7EtIgpnzl/G4ycJqFLFFE1dGiB4aAA+sayhi7dHH7BSuTWCvr6+rkN4bxkbG2H/vj+QmZWJgYH/gyAImD5tIg78FY7GTb2Qnp6h6xCpjOE5Rapat3k7Pq5hjq+HBcDCvBqu34zF0jWb8O/ZC9i4YgH09PQgCAKCJk3Fo8dP8O2YETCtZILfNmzFoOAQbFsXihrm1QEAUQejcftuHPp/0RU2dWriacJzLF/3O/oEjsa2dUvwsUV1Hb/b9x+3Rsij02QqICAAEolEqb1///4K7RKJBGfOnCnJ0N5bgwP7o27dmnB0aoPY2HsAgEuXruH61eMYOsQPvyxaqdsAqczhOUWqCp07FWZVq4iPXRu7wNS0Er6bMR//nrsIt6aNcPh4DM5dvIo1v/6E5k0bAgAaOtVHh15fYc2mbfh2zAgAQGD/LxTGAoDGLo7o0GsgtkdEIWiIf0m9LSLdJVNBQUG6eukPmm/nz3Hy5Fnxlx4A3Lv3AP/88y+6+H7OX3ykNp5TpKq3kx8AcKpvDwB4kvAcAHD4eAzMq30kJlIAUMmkIj5t5YbDx2LEZCq/sSxrWKBqlcp48ux58QdPSrg1Qh4mUx8YR0d7REj/Umq/cvUmevXsrIOIqKzjOUWaOH3uEgCgbi1rAEDsnfuwrau8bta2bi1E7D2I9PQMVKhgnO9YsffikJiULI5FVFJK9Q7oVPzMzKogOTlZqT0pKRlVq1Yu+YCozOM5Re/qScIzLPltA9ybNRYrVCmpaTCtpHz7MNNKlcTj+cnOzsGPPy+GWZXK6NG5g/aCJlEuBK38lEU6q0x98803BR4zMDCAmZkZ3Nzc0KJFixKMioiISkJ6egaCJ02Hvr4+Znw3RuPxZi5YivOXrmHJz9NQ2bRSMURIRSmr2xhog86SqcuXLxd4LCcnBwkJCVixYgXc3NywfPlyGBkZlWB076+kpBRUqVJFqb1q1SpISkop+YCozOM5Rep6mZmJUROn4uGjx1i3ZK54hR4AmFYygSyf6pMsNRUAUDmfqtXCZWuwLSIKMyePQyu3ptoLnKgAOkumpFJpkX1iYmIwevRohIaGYvz48SUQ1fvv6tWbaOBor9TuWN8O167d1EFEVNbxnCJ1vMrOxpjvZuLK9VtY9ctMhb2jAMCmTk2cOHVW6Xmxd+PwsYW50nqpFWG/Y/XGcHw7ZgS6dGyv1dhJUS4XoItK9Zopd3d3jBgxAnv37tV1KO8NaeRfcHNrgjp1aopttWp9gpYtXSGN3K/DyKis4jlFqsrNzUXItLk4deYCfv3pezR0qq/Up52HO54kPMe/5y6KbWkvXuDI3yfRzsNNoe/G8F1YvHI9Rg8NQL9eXbQeP1FBJEIpv7bxxIkTGDJkSKHTgvkpZ2ilpYjKtgoVjHH29H5kvHyJKT/MhSAImDZ1IiqZVETjpl548SJd1yFSGcNz6t1kPDqm6xBK3PSfF+OPnXswNOBLtG3ZXOGYhXk11DCvjtzcXPiNGI//niZg3KhAVK5UCas2bMXN23exPWypuBnnngNHMGnqXLRya4oRA/spjGVSsQJs6nx4d9IwqFa3RF+vtZV2KoHH4g9qZVxtKvXJ1J49ezBt2jScPHlSrecxmSqYtbX81h9tIJFIcOjwcYwd9wPu33+o69CojOI5pb4PMZn6vGcAHv33NN9jIwb1x6jAAQBe307m59BVOHT0BLKyXqGhUz1MCB6KenZ5ycJ3M+ZjV9SBfMdq1tgZ60LnFv8bKOVKOplqZeWplXH/jj+klXG1qVQnUzk5ORgwYACqVKmCZcuWqfVcJlNEVJp9iMkUaReTKd3R2QL0tWvXFnhMfjXfkSNH8PTpU/z+++8lGBkREREVpazuCaUNOkum5syZU+AxfX19VK1aFW5ubhg+fDjs7OxKMDIiIiIi1eksmbp+/bquXpqIiIg0VIpXCZU4nW2NsGDBAjx58kShLTo6Gmlpipu1xcXFYdy4cSUZGhERERWBt5PJo7NkatWqVQrJVE5ODoYPH4779+8r9EtKSsKePXtKOjwiIiIilehsmi+/8iBLhkRERGUD782Xp1TvgE5ERERU2umsMkVERERll65nk6KioiCVSnHlyhWkpKTA2toaffv2xZdffgk9vde1opCQEPz5559Kz120aBE6duxYbLGUumRKIpHoOgQiIiIq5dauXQtLS0tMnDgRH330EU6ePImZM2fiwYMHmDRpktjP2toa8+bNU3hu7dq1izUWnSZTAQEBSslT//79Fdp0nfkSERGRMl1febd8+XKYmZmJj93d3ZGeno5NmzZhzJgxMDQ0BAAYGRmhUaNGWo1FZ8lUUFCQrl6aiIiINKTrYsebiZRc/fr1kZmZieTkZJibm5dYLEymiIiIqNSQyWSQyWRK7aampjA1NS30uWfOnEGVKlXw0UcfiW1xcXFo1qwZMjIyYGdnh6FDh8Lb27tYYy51a6aIiIio9NPWNF9YWBhCQ0OV2oOCghAcHFzg8y5duoQdO3Zg1KhR0NfXB/C6UuXs7AxbW1ukpqZi27ZtGDNmDF6+fIkePXoUW8wSQdd1Oi0pZ2il6xCIiAqU8eiYrkOg94xBtbol+noNa7TUyrjHbu5VuzKVkJCA3r17w8LCAhs2bICBgUGB4/v7++PBgwc4fPhwscXMyhQRERGpTVubdqoynfem1NRUDBkyBEZGRli2bFmhiRQAdOzYEdOmTUNiYmK+667eBZMpIiIiUltuKZjYyszMxIgRI/D8+XNs2bIFVatW1UkcTKaIiIiozMnOzsbXX3+NGzduYMOGDbCyKnp5jyAIiIqKgpWVVbFVpQAmU0RERPQOdH1vvunTp+Pw4cOYMGECXr58ifPnz4vHbG1tkZKSgpCQEPj4+KBWrVqQyWQIDw/HqVOnMHfu3GKNhckUERERlTnHjx8HAPz8889Kx9avXw8HBweYmJhg2bJleP78OQwMDODo6Ihly5bB09OzWGPh1XxERDrAq/mouJX01Xz1zZtrZdxrT09pZVxtYmWKiIiI1Kbrab7SRE/XARARERGVZaxMERERkdpKw9YIpQUrU0REREQaYGWKiIiI1MY1U3lYmSIiIiLSACtTREREpDaumcrDZIqIiIjUxmm+PJzmIyIiItIAK1NERESkNkHI1XUIpQYrU0REREQaYGWKiIiI1JbLNVMiJlNERESkNoFX84k4zUdERESkAVamiIiISG2c5svDyhQRERGRBliZIiIiIrVxzVQeJlNERESkNt5OJg+n+YiIiIg0wMoUERERqY335svDyhQRERGRBliZIiIiIrVxAXoeVqaIiIiINMDKFBEREamNm3bmYTJFREREauM0Xx5O8xERERFpgJUpIiIiUhs37czDyhQRERGRBliZIiIiIrVxzVQeJlNERESkNl7Nl4fTfEREREQaYGWKiIiI1MZpvjysTBERERFpgJUpIiIiUhu3RsjDZIqIiIjUJnABuojTfEREREQaYGWKiIiI1MZpvjysTBERERFpgJUpIiIiUhu3RsjDyhQRERGRBliZIiIiIrXxar48rEwRERGR2gRB0MqPOu7du4fAwEA0btwY7u7u+PHHH5GRkaGld1wwVqaIiIiozJHJZPD394elpSUWLVqExMREzJ49G4mJiVi4cGGJxsJkioiIiNSm6wXoW7ZsgUwmw86dO2FmZgYA0NfXx/jx4zFy5EjY2dmVWCyc5iMiIqIy5+jRo3B3dxcTKQDo0KEDDA0NcfTo0RKNhZUpIiIiUpu26lIymQwymUyp3dTUFKampuLj2NhY9OzZU6GPoaEhatasiTt37mgpuvy9t8lUdla8rkMgIiJ6b2nr9+zixYsRGhqq1B4UFITg4GDxsUwmU0iu5ExNTZGSkqKV2Ary3iZTREREVPYEBASge/fuSu35JU6lBZMpIiIiKjXens4rrF9+04EymQx169bVRmgF4gJ0IiIiKnNsbGwQGxur0JaVlYW4uDgmU0RERERFadOmDWJiYpCUlCS27d+/H1lZWWjbtm2JxiIRdL1RBBEREZGaZDIZOnfuDCsrK4wcORLPnz/HTz/9hBYtWpT4pp1MpoiIiKhMunv3LmbMmIEzZ86gfPny8PHxwYQJE2BsbFyicTCZIiIiItIA10wRERERaYDJFBEREZEGmEwRERERaYDJ1Hvoyy+/hIODAw4dOqR0zMHBId+f8PBwAMDJkycV2hs3bgxfX1+EhYUhJyenpN8K6dDixYsLPF/mzZun0Pfu3btwcHBAy5YtCzxPoqOjMWDAALi5uaFRo0b47LPPMH78eNy9e7ck3g7pmCrnk4ODA1avXp3v8zt37oyQkJACx3Nzc0Pfvn0RHR1dIu+H6E3cAf098+DBA5w7dw4AIJVK4enpqdTHz88PnTt3VmirWbOmwuPZs2ejbt26SE1NRUREBGbNmoXMzEwMHTpUe8FTqWNkZISwsDCldgsLC4XHUqkUAPD8+XP8/fffaNOmjcLxPXv2YMyYMejWrRsCAwNhaGiIO3fuICoqCrGxsahTp4723gSVGqqeT+8yXkJCAlasWIHhw4dj06ZNaNKkiUaxEqmDydR7RiqVQiKRoEWLFjh06BDS0tJgYmKi0Ofjjz9Go0aNCh3Hzs4Ozs7OAAAPDw9cuXIF27dvZzL1gdHT0yvyXAGAyMhINGrUCDdv3oRUKlVKpjZs2AA3NzfMmTNHbGvVqhX8/PyQm5tb3GFTKaXq+fSu47m4uKBt27bYuXMnkykqUZzme89IpVI0adIEQ4cOxcuXL3HgwAGNx5RIJLC3t8fjx4+LIUJ635w/fx73799Hr1698Nlnn+HAgQPIyMhQ6COTyVC9evV8n6+nx68hKh4WFhYwMzPDo0ePdB0KfWD4LfYeuXz5Mu7cuYPOnTvDzc0NFhYW4vTLm3Jzc5GdnS3+qLIW6vHjx0pTgfRhePNckf+8uT2dVCqFoaEhOnToAF9fX6Snp+PgwYMKYzRo0AD79u3D6tWr8fDhw5J+C1SKFHU+aSI9PR0pKSn8rqISx2TqPSKVSlGuXDl07NgRenp68PHxwYkTJ/Ds2TOFfvPmzUODBg3En7enZIC8hCs5ORnr1q3DxYsXERQUVFJvhUqJ9PR0hXNF/nPkyBEAr38x7tmzB23atIGpqSlatmyJatWqKSXx48aNg729PebOnYv27dvDw8MDkydPxvXr13XwrkhXijqf3oU8IXv8+DG+//57mJiYwN/fv/iCJlIB10y9J3JycrB79260atUKZmZmAIAuXbpgzZo12L17NwICAsS+/v7+6NKli/jYwMBAabzevXsrPB4xYgQ6duyopeiptDIyMsLGjRuV2mvXrg0A+Pvvv5GYmChe0KCvrw9vb29s3rwZiYmJ4rloYWGBbdu24d9//8WxY8dw+vRpbN++HTt37sSSJUtK/KakpBtFnU/qkidncuXKlcPy5cvfeTyid8Vk6j0RExODhIQEtGvXDjKZDABgZWWF2rVrQyqVKiRTNWrUEBeXF2TOnDmwsbFBYmIiVqxYgeXLl8PV1RWtWrXS6vug0kVPT6/QcyUiIgLGxsZo1qyZeN55enpi/fr1iIqKQv/+/RXGcnNzg5ubGwDg6tWrGDBgAH755RcmUx+Ios4nfX39Apcd5OTkoFw5xV9Z8uRMEATcu3cP8+fPx/jx47F7925Uq1atWGMnKgyTqfeEfFpl6tSpmDp1qtLxe/fuqfXXmo2Njfil16xZM3Ts2BGzZ88WrxYkSk9Px6FDh5CRkQEPDw+l41KpVCGZepujoyNatWrFfYFIZGZmhoSEhHyPJSQk4KOPPlJoezM5c3FxQZ06ddC7d2+Ehobm+z1IpC1Mpt4DL1++xF9//YV27dph4MCBCsfS0tIwatQoSKVSBAcHv9P4FStWxOjRozF58mQcOHAAn332WXGETWXc/v37kZ6ejilTpsDW1lbh2L59+7Bp0yY8ePAA1tbWePbsmVKlIDc3F/fv32cFgUTNmzdHdHQ0Jk6cqLD8ICYmBqmpqXB1dS30+c7OzvDx8cH27dsxcuRImJubaztkIgBMpt4Lhw4dwosXL+Dn5ydOobypefPmGiVTANCtWzcsX74cK1asYDL1AcnNzcX58+eV2qtWrQqpVIoaNWqgb9++StsbWFlZYfPmzYiMjMSIESMwePBg1K5dG+3atYOVlRWSkpKwfft23LhxA99++20JvRvStcLOp1q1amH48OHo3bs3/Pz84OfnBzMzM1y/fh1Lly5F8+bNVVpmMHLkSOzZswfr1q3DxIkTtfAuiJQxmXoPREREwMLCAi1atMj3ePfu3RESEoKLFy++82sYGBhg+PDhmDx5Mk6cOFHga9H75eXLl+jTp49Su5ubG86cOYNBgwblu0/UJ598AldXV0ilUowYMQJDhgxBVFQUFi1ahISEBFSqVAl169bF4sWL8fnnn5fEW6FSoKDzydvbGwsXLoS9vT02b96MX3/9FVOnTkV6ejosLCzQq1cvBAcHq7TEoG7duvD29saWLVswfPhwmJqaauOtECmQCMW1wQcRERHRB4j7TBERERFpgMkUERERkQaYTBERERFpgMkUERERkQaYTBERERFpgMkUERERkQaYTBHRO5FvrCj38OFDODg4YMeOHTqMStHixYvh4OCg6zCI6D3HZIqojNqxYwccHBzEH0dHR7Rp0wbffPMNnjx5ouvwVHb79m0sXrwYDx8+1HUoRETvhDugE5VxwcHBsLa2RlZWFs6ePYudO3fi1KlTiIyMhLGxcYnFYWVlhYsXL6JcOfW+Vm7fvo3Q0FA0b94cn3zyiZaiIyLSHiZTRGWch4cHGjVqBAD44osvULlyZaxduxYHDx5E586dlfqnp6ejQoUKxR6HRCJB+fLli31cIqLSjtN8RO8Zd3d3AK/XMIWEhMDZ2RkPHz7E8OHD0aRJEwwbNkzsK5VK0bNnT7i4uMDV1RWjR4/GgwcPlMbcunUrvLy84OLigl69euH06dNKfQpaM/X06VNMmTIFbdq0gZOTEzw9PTF58mSkpaVhx44d+PrrrwEA/v7+4pTlm2NcvHgRQ4YMQdOmTeHi4oK+ffsiJiZG6fVPnz6Nnj17wtnZGV5eXtiyZcu7fYBERGpiZYroPRMXFwcAqFKlCgBAEAQEBgbC2dkZEydOhL6+PgBg5cqVWLBgATp06IAePXpAJpNh06ZN6Nu3LyIiImBmZgYACA8Px5QpU9C4cWP4+/vj0aNHGDlyJExNTfHxxx8XGktCQgK++OILJCUloXfv3rCzs8PTp0+xf/9+JCcnw9XVFX5+ftiwYQOGDx+OunXrAgCaNGkCADh16hQCAwNRv359jBo1CuXKlcOuXbsQGBiINWvWwM3NDQBw48YNBAYGwszMDMHBwcjJyUFoaKj4HoiItInJFFEZl5qaisTERHHN1JIlS2BkZIR27drh/PnzePXqFT799FN888034nMePXqERYsWISgoCEFBQWK7j48PfHx8sG7dOowdOxavXr3CwoULUb9+faxfvx6GhoYAAFtbW3z33XdFJlPz58/H06dPsWXLFjRs2FBsDw4OhiAIkEgkaNasGTZs2ICWLVuKyRHwOgmcMmUKmjZtirVr10IikQAAvvzyS3Tv3h0LFy4Uq0+//vorcnNzsWnTJlhaWgIAOnbsmO80JxFRcWMyRVTGDR48WOGxra0tJk+eDAsLC7GtX79+Cn3++usvZGdnw9vbG4mJiWK7iYkJ7O3tcfLkSQDA5cuX8fz5c4waNUpMpACgW7dumDNnTqFx5ebmYv/+/WjTpo1CIiUnT44Kcv36ddy9exeDBw9GUlKSwrGWLVti48aNyMjIgKGhIY4fPw5PT08xkQKAOnXqwMPDA0eOHCn0dYiINMVkiqiMmzx5MmxsbGBoaAhLS0t8/PHHComKnp4erKysFJ5z7949AECnTp3yHdPa2hrA6woWANSuXVvheLly5Yq88i4xMRFpaWmws7NT5+2I7t69CwD47rvvCuyTnJyMcuXK4eXLl0oxAspxExFpA5MpojLO2dlZvJovP+XKlVPariA3NxcAsGrVqny3MigNV+UJggAAGDduHJycnPLtY2ZmBplMVpJhEREpYTJF9AGqWbMmAMDS0hK2trYF9pNPm927dw+tWrUS27Ozs/Hw4UPUq1evwOeamZnBxMQEt27dKjSWgqb75NWxihUromXLloW+jpGRkVhte1N+bURExY1bIxB9gDp06AB9fX0sWbJErAC9Sb6OysnJCWZmZggPD0dWVpZ4fOfOnUVWhPT09PDZZ5/h6NGjuHDhgtJx+evKNxZ9ezwnJyfUqlUL69atQ1paWoEx6uvrw8PDA4cPHxanJYHX04THjx8vNEYiouLAyhTRB8ja2hrjxo3D3Llz8ejRI7Rv3x6mpqZ4+PAhDh48CG9vbwQHB8PAwAD/+9//MGXKFPj7+8PHxwfx8fHYsWOHWDkqzNixY/H333/Dz88Pffr0ga2tLZ49e4b9+/cjNDQUn3zyCRwdHaGvr48VK1ZAJpPByMgILi4usLa2xsyZMzF48GD4+PigZ8+eqFGjBp4+fYpTp05BEARs2LABwOurA48dO4b+/fujb9++yM3NxcaNG2FjY4MbN25o++Mkog8ckymiD1RgYKBY+Vm2bBkEQYCFhQXc3d3RsWNHsV+fPn2Qk5OD1atXY+7cubC3t8fSpUuxaNGiIl/D3Nwc4eHhWLRoEXbv3g2ZTAZzc3N4eHigatWqAIBq1arhxx9/xIoVK/D9998jJycHs2fPhrW1NVxdXbF161YsXboUmzdvRlpaGqpXrw5nZ2f06tVLfJ169eph9erVmD17Nn799VfUqFEDQUFBSEhIYDJFRFonEfKr8RMRERGRSrhmioiIiEgDTKaIiIiINMBkioiIiEgDTKaIiIiINMBkioiIiEgDTKaIiIiINMBkioiIiEgDTKaIiIiINMBkioiIiEgD/wdgLcmj9sxaKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating and visualizing the confusion matrix\n",
    "labs = np.unique(pred_df[['Population', 'Prediction']])\n",
    "cm = confusion_matrix(pred_df.Population, pred_df.Prediction, labels=labs)\n",
    "cm_plot = plot_cm(cm,title='Confusion matrix when using real EAS,AFR and artifical EUR', normalize=False, labels=labs)\n",
    "cm_plot.figure.savefig(f'{output_basename}confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to visualize population SNP on the chromosome."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import Image\n",
    "from lainet.visualization import plot_cm, plot_chm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sample_id = \"HG020from IPython.display import Image\n",
    "from lainet.visualization import plot_cm, plot_chm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sample_id = \"HG02075\" # looking at just one random sample\n",
    "img_name = f\"{output_basename}{sample_id}_chm_img\"\n",
    "palette= sns.color_palette([\"#A60303\", \"#3457BF\", \"#75BFAA\", \"#613673\"]).as_hex()\n",
    "plot_chm(sample_id, msp_df,output_basename,output_file,palette=palette, img_name=img_name)\n",
    "Image(filename=img_name+\".png\",retina=True)75\" # looking at just one random sample\n",
    "img_name = f\"{output_basename}{sample_id}_chm_img\"\n",
    "palette= sns.color_palette([\"#A60303\", \"#3457BF\", \"#75BFAA\", \"#613673\"]).as_hex()\n",
    "plot_chm(sample_id, msp_df,output_basename,output_file,palette=palette, img_name=img_name)\n",
    "Image(filename=img_name+\".png\",retina=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mon Python",
   "language": "python",
   "name": "ter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
